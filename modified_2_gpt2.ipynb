{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOUQUYSjaYAKLigMDAroaoE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de2e4bb92ce34023bc15b10004f2b2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56808b42156d4aea8146f9d69bbe9844",
              "IPY_MODEL_c93aa66bb5624939a95f260e18fbe5dc",
              "IPY_MODEL_93d7b5a825424a269992be094ff9ac4e"
            ],
            "layout": "IPY_MODEL_d2cc1a6d3f3042c3af505ddcb6718dcc"
          }
        },
        "56808b42156d4aea8146f9d69bbe9844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe20cd549d454ebc95e7734bfa4767a6",
            "placeholder": "​",
            "style": "IPY_MODEL_30aa1de8348247259640eb107d6a1ce0",
            "value": "config.json: 100%"
          }
        },
        "c93aa66bb5624939a95f260e18fbe5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a492652a24b4fe2aae4a5c7deeef5c7",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88d7599342ba41318c2541ffb7b2d49f",
            "value": 665
          }
        },
        "93d7b5a825424a269992be094ff9ac4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1e6ac5df5064d9fb8ce98b78fc1414b",
            "placeholder": "​",
            "style": "IPY_MODEL_fc541ae92a524981b439759dfac89291",
            "value": " 665/665 [00:00&lt;00:00, 52.2kB/s]"
          }
        },
        "d2cc1a6d3f3042c3af505ddcb6718dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe20cd549d454ebc95e7734bfa4767a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30aa1de8348247259640eb107d6a1ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a492652a24b4fe2aae4a5c7deeef5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d7599342ba41318c2541ffb7b2d49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1e6ac5df5064d9fb8ce98b78fc1414b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc541ae92a524981b439759dfac89291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8954034f5e704d87911ad7155393fe63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ef704e034614b2a9b00a7db918cf74c",
              "IPY_MODEL_fed5d7f3c02849378d4e46410e1e9acd",
              "IPY_MODEL_3a8b0e7e269d48cfb5e7ebd36b7985f1"
            ],
            "layout": "IPY_MODEL_764c7b4ad5ab4b56b824ad91f113b351"
          }
        },
        "0ef704e034614b2a9b00a7db918cf74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bbdd64d0b67429eba3ed91e601ab56f",
            "placeholder": "​",
            "style": "IPY_MODEL_a6586a633e524e51b5b88099a1532c2d",
            "value": "model.safetensors: 100%"
          }
        },
        "fed5d7f3c02849378d4e46410e1e9acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19a267ad9f6c46d2b0550bfd64b0cac2",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_849d88a3c17e4d80b776ca152b17852a",
            "value": 548105171
          }
        },
        "3a8b0e7e269d48cfb5e7ebd36b7985f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6f3ffd333f646f88dfac440261d513b",
            "placeholder": "​",
            "style": "IPY_MODEL_a4375e5aa9ef4146845d67bc6b11035c",
            "value": " 548M/548M [00:05&lt;00:00, 179MB/s]"
          }
        },
        "764c7b4ad5ab4b56b824ad91f113b351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bbdd64d0b67429eba3ed91e601ab56f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6586a633e524e51b5b88099a1532c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19a267ad9f6c46d2b0550bfd64b0cac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "849d88a3c17e4d80b776ca152b17852a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6f3ffd333f646f88dfac440261d513b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4375e5aa9ef4146845d67bc6b11035c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00199614e53147fab867ff80c017eea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_296bfcd9f0914a3ea1f28cc60538a9f5",
              "IPY_MODEL_7b4883c0cf1a4c019b1509c184f6e990",
              "IPY_MODEL_f7e254535dbc48ee9be8326140c6e750"
            ],
            "layout": "IPY_MODEL_608c27c0f1bc4134b87a6c39a3972bfd"
          }
        },
        "296bfcd9f0914a3ea1f28cc60538a9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d09fca86d2314406baf7610bf0d5ce07",
            "placeholder": "​",
            "style": "IPY_MODEL_304ffa4b6e724f4d9809ca676ecf7b5f",
            "value": "generation_config.json: 100%"
          }
        },
        "7b4883c0cf1a4c019b1509c184f6e990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d79e5a76d55a43168c82c829116eba67",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb6504ad243c4a12994f7709d10ab1dd",
            "value": 124
          }
        },
        "f7e254535dbc48ee9be8326140c6e750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f9e19761a484335a396b47aacea90c7",
            "placeholder": "​",
            "style": "IPY_MODEL_d52027d42380457199eee0df3da6cbd1",
            "value": " 124/124 [00:00&lt;00:00, 7.60kB/s]"
          }
        },
        "608c27c0f1bc4134b87a6c39a3972bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d09fca86d2314406baf7610bf0d5ce07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "304ffa4b6e724f4d9809ca676ecf7b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d79e5a76d55a43168c82c829116eba67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb6504ad243c4a12994f7709d10ab1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f9e19761a484335a396b47aacea90c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d52027d42380457199eee0df3da6cbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dce1bb9da22b471f9e91eadf7d53355f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfe750aa0acc4a238f479767ce506cba",
              "IPY_MODEL_66f18a7d8ca84f65b2f2eee8bcd30893",
              "IPY_MODEL_fe0ab034a86a4d5ab55b1f4c3a3ff224"
            ],
            "layout": "IPY_MODEL_3e4d5919f4bf4d0d92239d8503dd41b1"
          }
        },
        "dfe750aa0acc4a238f479767ce506cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53e523508600427aa5002f7de2fdf291",
            "placeholder": "​",
            "style": "IPY_MODEL_6992cbb9e18c4bc493ad942da8a7f652",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "66f18a7d8ca84f65b2f2eee8bcd30893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a701bcc94984047bff110e265ad24e8",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8e3403792e241fdac24551c15cdc135",
            "value": 26
          }
        },
        "fe0ab034a86a4d5ab55b1f4c3a3ff224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_154599ada7ee4aa786ac5fe35d21df55",
            "placeholder": "​",
            "style": "IPY_MODEL_f66aec5360ca404fa956fbd4e39bd1a2",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.34kB/s]"
          }
        },
        "3e4d5919f4bf4d0d92239d8503dd41b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e523508600427aa5002f7de2fdf291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6992cbb9e18c4bc493ad942da8a7f652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a701bcc94984047bff110e265ad24e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e3403792e241fdac24551c15cdc135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "154599ada7ee4aa786ac5fe35d21df55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66aec5360ca404fa956fbd4e39bd1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b74046edc8d44f4094ab319d9db436de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d05eb9b8e8d4406a939272ff8c16efe4",
              "IPY_MODEL_cbb075e1cbd4451e896cc8b343593c49",
              "IPY_MODEL_d7133f14a10e4f77a75ab84b40b43de4"
            ],
            "layout": "IPY_MODEL_aa4f39b06f854038a1d20993ee67c824"
          }
        },
        "d05eb9b8e8d4406a939272ff8c16efe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83650704301c41e2ab1bce8ca8ae23dc",
            "placeholder": "​",
            "style": "IPY_MODEL_2e31b41dd57a4ca292eb53ea0bcc7407",
            "value": "vocab.json: 100%"
          }
        },
        "cbb075e1cbd4451e896cc8b343593c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09916d5762734c74b698004f87050fc6",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efbf3b2df0184f06a204e1db3398be58",
            "value": 1042301
          }
        },
        "d7133f14a10e4f77a75ab84b40b43de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c29b24286192467dbdb31f137166e510",
            "placeholder": "​",
            "style": "IPY_MODEL_8173c96ad2474ad8ad2ba8021c897379",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.09MB/s]"
          }
        },
        "aa4f39b06f854038a1d20993ee67c824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83650704301c41e2ab1bce8ca8ae23dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e31b41dd57a4ca292eb53ea0bcc7407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09916d5762734c74b698004f87050fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efbf3b2df0184f06a204e1db3398be58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c29b24286192467dbdb31f137166e510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8173c96ad2474ad8ad2ba8021c897379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a250f8d4f2f5482fb0d84eed2d61ec8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9688973c4e04a0c8c85400acb733672",
              "IPY_MODEL_caecfed1d336416e920a76419c436890",
              "IPY_MODEL_1459c353052e4952a795ac03d0477273"
            ],
            "layout": "IPY_MODEL_24a758951a0e401b8848a632c6316b7c"
          }
        },
        "e9688973c4e04a0c8c85400acb733672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d01964b34794343a42c6a96bbf9ffd8",
            "placeholder": "​",
            "style": "IPY_MODEL_474b103f2eb94b189097ffb052f93751",
            "value": "merges.txt: 100%"
          }
        },
        "caecfed1d336416e920a76419c436890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_319138a7940f40098c71389db8a7ce0b",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_685090c92f42481cb0d44c2ce4a16f82",
            "value": 456318
          }
        },
        "1459c353052e4952a795ac03d0477273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_440bbd6712494f3c8f1ffe53e486ce70",
            "placeholder": "​",
            "style": "IPY_MODEL_7c66e8cb0d5c437b95dcad0d7e9d2db6",
            "value": " 456k/456k [00:00&lt;00:00, 3.46MB/s]"
          }
        },
        "24a758951a0e401b8848a632c6316b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d01964b34794343a42c6a96bbf9ffd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474b103f2eb94b189097ffb052f93751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "319138a7940f40098c71389db8a7ce0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "685090c92f42481cb0d44c2ce4a16f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "440bbd6712494f3c8f1ffe53e486ce70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c66e8cb0d5c437b95dcad0d7e9d2db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e09fa5c3de44698bc0e34c706c6c070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b791551b28bd46ea8642a6c7801998ab",
              "IPY_MODEL_94ddb1f3b88f46baa727743eae49edb4",
              "IPY_MODEL_3fa2eaedb1744d7e9a08444817f978bf"
            ],
            "layout": "IPY_MODEL_690c719c185244bfa420e21cafb7cdc9"
          }
        },
        "b791551b28bd46ea8642a6c7801998ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_459e98833168493ebcb7dfa84bf7f787",
            "placeholder": "​",
            "style": "IPY_MODEL_be4c9c835d2e4c7cbb0cacbcc6b5ef5a",
            "value": "tokenizer.json: 100%"
          }
        },
        "94ddb1f3b88f46baa727743eae49edb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4764e41a21b44b3d97c690814c0eace7",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86399e37a2b64e59950200e97f213740",
            "value": 1355256
          }
        },
        "3fa2eaedb1744d7e9a08444817f978bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b3b9a1d5f0b436ea56ea8471af2ff7c",
            "placeholder": "​",
            "style": "IPY_MODEL_eb7c244e88d6401d9ae5d502dd49169d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 16.8MB/s]"
          }
        },
        "690c719c185244bfa420e21cafb7cdc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "459e98833168493ebcb7dfa84bf7f787": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be4c9c835d2e4c7cbb0cacbcc6b5ef5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4764e41a21b44b3d97c690814c0eace7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86399e37a2b64e59950200e97f213740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b3b9a1d5f0b436ea56ea8471af2ff7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb7c244e88d6401d9ae5d502dd49169d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asad-Khan9/GPT-2-Flash-Attention-Data-Chunk-Optimization/blob/main/modified_2_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34xuMw_BwMqW",
        "outputId": "f5330f72-d255-43e9-fe4f-7af31d08023c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh7G__E4wSE5",
        "outputId": "c1aba11d-d419-448f-daaa-f7b3e06622de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import tiktoken\n",
        "import datasets\n",
        "# URL for Alice's Adventures in Wonderland from Project Gutenberg\n",
        "url = 'https://www.gutenberg.org/files/11/11-0.txt'\n",
        "\n",
        "# Fetch the dataset (book)\n",
        "response = requests.get(url)\n",
        "\n",
        "# Save it to input.txt\n",
        "full_text = response.text\n",
        "\n",
        "# Define the split ratio (80% train, 20% test)\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(full_text) * split_ratio)\n",
        "\n",
        "# Split the dataset\n",
        "train_text = full_text[:split_index]\n",
        "test_text = full_text[split_index:]\n",
        "\n",
        "# Write to input.txt (full dataset)\n",
        "with open('input.txt', 'w') as f:\n",
        "    f.write(full_text)\n",
        "\n",
        "# Write to train.txt (80% of the dataset)\n",
        "with open('train.txt', 'w') as f:\n",
        "    f.write(train_text)\n",
        "\n",
        "# Write to test.txt (20% of the dataset)\n",
        "with open('test.txt', 'w') as f:\n",
        "    f.write(test_text)\n",
        "\n",
        "print(\"Dataset written to input.txt, train.txt (80%), and test.txt (20%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV-B8OxPwSHO",
        "outputId": "99cf3ae4-f172-48fb-f98f-949e66bd7c10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset written to input.txt, train.txt (80%), and test.txt (20%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import inspect\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "B8S3dpUpwSJr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flash_attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70wMOlgsww3I",
        "outputId": "36f7013b-6df5-453e-c28b-887bc0a64d25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash_attn\n",
            "  Downloading flash_attn-2.7.3.tar.gz (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash_attn) (2.5.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash_attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->flash_attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash_attn) (3.0.2)\n",
            "Building wheels for collected packages: flash_attn\n",
            "  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash_attn: filename=flash_attn-2.7.3-cp310-cp310-linux_x86_64.whl size=191342964 sha256=cd0ead6ad92bff21f90cf0aecdf859bc7145bf4e7dc8ed1fdc3cc38299651ce4\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/d7/10/a74c9fe5ffe6ff306b27a220b2bf2f37d907b68fdcd138cdda\n",
            "Successfully built flash_attn\n",
            "Installing collected packages: flash_attn\n",
            "Successfully installed flash_attn-2.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import inspect\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "try:\n",
        "    from flash_attn import flash_attn_func\n",
        "    FLASH_AVAILABLE = True\n",
        "except ImportError:\n",
        "    FLASH_AVAILABLE = False\n",
        "    print(\"Flash attention not available. Using standard attention.\")\n",
        "\n",
        "class CausalSelfAttention(nn.Module):  #Improved attention module\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "\n",
        "        # Configuration\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.use_flash = getattr(config, 'use_flash_attention', False) and FLASH_AVAILABLE\n",
        "        self.window_size = getattr(config, 'window_size', None)\n",
        "\n",
        "        # Key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        # Output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "\n",
        "        # Causal mask buffer\n",
        "        if not self.use_flash:\n",
        "            self.register_buffer(\n",
        "                \"bias\",\n",
        "                torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                .view(1, 1, config.block_size, config.block_size)\n",
        "            )\n",
        "\n",
        "    def _flash_attention(self, q, k, v):\n",
        "\n",
        "        # Reshape for flash attention\n",
        "        q = q.transpose(1, 2)  # [B, T, H, D]\n",
        "        k = k.transpose(1, 2)\n",
        "        v = v.transpose(1, 2)\n",
        "\n",
        "        # Apply flash attention\n",
        "        output = flash_attn_func(q, k, v, causal=True)\n",
        "        return output.transpose(1, 2)  # Return to original shape\n",
        "\n",
        "    def _sliding_window_attention(self, q, k, v, T):\n",
        "        # Sliding window attention implementation\n",
        "        att = torch.zeros_like(q @ k.transpose(-2, -1))\n",
        "        window_size = min(self.window_size, T) if self.window_size else T\n",
        "\n",
        "        for i in range(0, T, window_size):\n",
        "            end_idx = min(i + window_size, T)\n",
        "            # Calculate attention scores for the current window\n",
        "            scores = (q[:, :, i:end_idx] @ k[:, :, max(0, i-window_size):end_idx].transpose(-2, -1))\n",
        "            scores = scores * (1.0 / math.sqrt(k.size(-1)))\n",
        "\n",
        "            # Apply causal mask within the window\n",
        "            window_mask = self.bias[:, :, i:end_idx, max(0, i-window_size):end_idx]\n",
        "            scores = scores.masked_fill(window_mask == 0, float('-inf'))\n",
        "            scores = F.softmax(scores, dim=-1)\n",
        "\n",
        "            # Update attention for the current window\n",
        "            att[:, :, i:end_idx] = scores @ v[:, :, max(0, i-window_size):end_idx]\n",
        "\n",
        "        return att\n",
        "\n",
        "    def _standard_attention(self, q, k, v, T):\n",
        "        # Regular attention implementation\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        return att @ v\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        # Calculate query, key, values for all heads in batch\n",
        "        qkv = self.c_attn(x)\n",
        "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
        "\n",
        "        # Reshape for attention\n",
        "        head_size = C // self.n_head\n",
        "        q = q.view(B, T, self.n_head, head_size).transpose(1, 2)\n",
        "        k = k.view(B, T, self.n_head, head_size).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, head_size).transpose(1, 2)\n",
        "\n",
        "        # Apply attention based on configuration\n",
        "        if self.use_flash:\n",
        "            y = self._flash_attention(q, k, v)\n",
        "        elif self.window_size:\n",
        "            y = self._sliding_window_attention(q, k, v, T)\n",
        "        else:\n",
        "            y = self._standard_attention(q, k, v, T)\n",
        "\n",
        "        # Reshape and apply output projection\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return self.c_proj(y)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
        "        self.gelu    = nn.GELU(approximate='tanh')\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
        "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = MLP(config)\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50257\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768\n",
        "    use_flash_attention: bool = False  # Added config for flash attention\n",
        "    window_size: int = None  # Added config for sliding window attention\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "        # init params\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            std = 0.02\n",
        "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
        "                std *= (2 * self.config.n_layer) ** -0.5\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # idx is of shape (B, T)\n",
        "        B, T = idx.size()\n",
        "        assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
        "        # forward the token and posisition embeddings\n",
        "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device) # shape (T)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (T, n_embd)\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (B, T, n_embd)\n",
        "        x = tok_emb + pos_emb\n",
        "        # forward the blocks of the transformer\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        # forward the final layernorm and the classifier\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "        return logits, loss\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type):\n",
        "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
        "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
        "        # n_layer, n_head and n_embd are determined from model_type\n",
        "        config_args = {\n",
        "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
        "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "        }[model_type]\n",
        "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
        "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
        "        # create a from-scratch initialized minGPT model\n",
        "        config = GPTConfig(**config_args)\n",
        "        model = GPT(config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
        "        # init a huggingface/transformers model\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
        "        # this means that we have to transpose these weights when we import them\n",
        "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
        "        for k in sd_keys_hf:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                # special treatment for the Conv1D weights we need to transpose\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                # vanilla copy over the other parameters\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, device):\n",
        "        # start with all of the candidate parameters (that require grad)\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {'params': decay_params, 'weight_decay': weight_decay},\n",
        "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "        # Create AdamW optimizer and use the fused version if it is available\n",
        "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "        use_fused = fused_available and 'cuda' in device\n",
        "        print(f\"using fused AdamW: {use_fused}\")\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=(0.9, 0.95), eps=1e-8, fused=use_fused)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "X6J1q3MywSN2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Tuple\n",
        "import json\n",
        "\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    batch_size: int = 4  # Default batch size (B)\n",
        "    sequence_length: int = 1024  # Default sequence length (T)\n",
        "    chunk_size: int = 2048  # Size of chunks to process text\n",
        "    overlap: int = 128  # Overlap between chunks to maintain context\n",
        "    num_workers: int = 4  # Number of workers for DataLoader\n",
        "    cache_dir: str = \"cache\"  # Directory to store cached tokenized data\n",
        "\n",
        "class ImprovedDataset(Dataset):\n",
        "    def __init__(self, file_path: str, config: DataConfig, train_mode: bool = True):\n",
        "        \"\"\"\n",
        "        Improved dataset class with caching and chunking.\n",
        "\n",
        "        Args:\n",
        "            file_path: Path to the input text file\n",
        "            config: Configuration for data processing\n",
        "            train_mode: If True, uses training data; if False, uses test data\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.train_mode = train_mode\n",
        "\n",
        "        # Create cache directory if it doesn't exist\n",
        "        Path(config.cache_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Determine cache file path\n",
        "        mode = \"train\" if train_mode else \"test\"\n",
        "        self.cache_file = Path(config.cache_dir) / f\"{mode}_cached.npy\"\n",
        "\n",
        "        # Load or create cached tokens\n",
        "        self.tokens = self._load_or_create_cache(file_path)\n",
        "\n",
        "        print(f\"Loaded {len(self.tokens)} tokens from {file_path}\")\n",
        "        print(f\"1 epoch = {len(self.tokens) // (config.batch_size * config.sequence_length)} batches\")\n",
        "\n",
        "        # Initialize position\n",
        "        self.current_position = 0\n",
        "\n",
        "    def _load_or_create_cache(self, file_path: str) -> torch.Tensor:\n",
        "        \"\"\"Load tokens from cache if available, otherwise create and cache them.\"\"\"\n",
        "        if self.cache_file.exists():\n",
        "            print(\"Loading from cache...\")\n",
        "            return torch.from_numpy(np.load(self.cache_file))\n",
        "\n",
        "        print(\"Cache not found. Processing text file...\")\n",
        "        return self._process_and_cache_file(file_path)\n",
        "\n",
        "    def _process_and_cache_file(self, file_path: str) -> torch.Tensor:\n",
        "        \"\"\"Process text file and create cache.\"\"\"\n",
        "        # Read text file\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "\n",
        "        # Clean text\n",
        "        text = self._clean_text(text)\n",
        "\n",
        "        # Tokenize\n",
        "        enc = tiktoken.get_encoding('gpt2')\n",
        "        tokens = enc.encode(text)\n",
        "\n",
        "        # Create chunks with overlap\n",
        "        chunks = []\n",
        "        for i in range(0, len(tokens), self.config.chunk_size - self.config.overlap):\n",
        "            chunk = tokens[i:i + self.config.chunk_size]\n",
        "            if len(chunk) >= self.config.sequence_length:\n",
        "                chunks.extend(chunk)\n",
        "\n",
        "        # Convert to numpy array and save cache\n",
        "        tokens_array = np.array(chunks, dtype=np.int64)\n",
        "        np.save(self.cache_file, tokens_array)\n",
        "\n",
        "        return torch.from_numpy(tokens_array)\n",
        "\n",
        "    def _clean_text(self, text: str) -> str:\n",
        "        \"\"\"Clean and preprocess text.\"\"\"\n",
        "        # Remove multiple newlines\n",
        "        text = '\\n'.join(line for line in text.split('\\n') if line.strip())\n",
        "        # Remove multiple spaces\n",
        "        text = ' '.join(text.split())\n",
        "        return text\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens) - self.config.sequence_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence and target\n",
        "        seq_len = self.config.sequence_length\n",
        "        tokens = self.tokens[idx:idx + seq_len + 1]\n",
        "        x = tokens[:-1]\n",
        "        y = tokens[1:]\n",
        "        return x, y\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_file: str,\n",
        "    test_file: str,\n",
        "    config: DataConfig\n",
        ") -> Tuple[DataLoader, DataLoader]:\n",
        "    \"\"\"Create train and test dataloaders.\"\"\"\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = ImprovedDataset(train_file, config, train_mode=True)\n",
        "    test_dataset = ImprovedDataset(test_file, config, train_mode=False)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=config.num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "# Initialize configuration\n",
        "config = DataConfig(\n",
        "    batch_size=4,  # Your original B\n",
        "    sequence_length=1024,  # Your original T\n",
        "    chunk_size=2048,\n",
        "    overlap=128,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Create train and test dataloaders\n",
        "train_loader, test_loader = create_dataloaders(\n",
        "    train_file='train.txt',\n",
        "    test_file='test.txt',\n",
        "    config=config\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRvG6LAgwSQX",
        "outputId": "523617a1-6bb0-4ef1-8813-dea64e732933"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache not found. Processing text file...\n",
            "Loaded 34209 tokens from train.txt\n",
            "1 epoch = 8 batches\n",
            "Cache not found. Processing text file...\n",
            "Loaded 8192 tokens from test.txt\n",
            "1 epoch = 2 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "print(f\"using device: {device}\")\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(1337)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFSxwSmhwSS0",
        "outputId": "76b86975-052b-4d17-9094-7b68251ee14d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "import time\n",
        "from torch.cuda.amp import autocast\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "\n",
        "# Initialize configuration and dataloaders\n",
        "config = DataConfig(\n",
        "    batch_size=4,  # Your original B\n",
        "    sequence_length=1024,  # Your original T\n",
        "    chunk_size=2048,\n",
        "    overlap=128,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Create train and test dataloaders\n",
        "train_loader, test_loader = create_dataloaders(\n",
        "    train_file='train.txt',\n",
        "    test_file='test.txt',\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# Initialize model\n",
        "model = GPT(GPTConfig())\n",
        "model.to(device)\n",
        "model = torch.compile(model)\n",
        "\n",
        "# Learning rate schedule configuration\n",
        "max_lr = 6e-4\n",
        "min_lr = max_lr * 0.1\n",
        "warmup_steps = 50\n",
        "max_steps = 500\n",
        "\n",
        "def get_lr(it):\n",
        "    # 1) linear warmup for warmup_iters steps\n",
        "    if it < warmup_steps:\n",
        "        return max_lr * (it+1) / warmup_steps\n",
        "    # 2) if it > lr_decay_iters, return min learning rate\n",
        "    if it > max_steps:\n",
        "        return min_lr\n",
        "    # 3) in between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
        "    return min_lr + coeff * (max_lr - min_lr)\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = model.configure_optimizers(weight_decay=0.1, learning_rate=6e-4, device=device)\n",
        "\n",
        "# Training loop\n",
        "step = 0\n",
        "for epoch in range((max_steps * config.batch_size) // len(train_loader) + 1):\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        if step >= max_steps:\n",
        "            break\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Move data to device\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with mixed precision\n",
        "        with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
        "            logits, loss = model(x, y)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update learning rate\n",
        "        lr = get_lr(step)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        # Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Wait for GPU\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "        # Calculate statistics\n",
        "        t1 = time.time()\n",
        "        dt = (t1 - t0) * 1000  # time difference in milliseconds\n",
        "        tokens_per_sec = (config.batch_size * config.sequence_length) / (t1 - t0)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"step {step:4d} | loss: {loss.item():.6f} | lr {lr:.4e} | \"\n",
        "              f\"norm: {norm:.4f} | dt: {dt:.2f}ms | tok/sec: {tokens_per_sec:.2f}\")\n",
        "\n",
        "        step += 1\n",
        "        if step >= max_steps:\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQfEEfvWwSVC",
        "outputId": "3c0370be-c1be-4ba3-9b41-bff03c6058ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading from cache...\n",
            "Loaded 34209 tokens from train.txt\n",
            "1 epoch = 8 batches\n",
            "Loading from cache...\n",
            "Loaded 8192 tokens from test.txt\n",
            "1 epoch = 2 batches\n",
            "num decayed parameter tensors: 50, with 124,318,464 parameters\n",
            "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
            "using fused AdamW: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:1604: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:1604: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:1604: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:1604: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:1604: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step    0 | loss: 11.027405 | lr 1.2000e-05 | norm: 22.2122 | dt: 25260.97ms | tok/sec: 162.15\n",
            "step    1 | loss: 10.337845 | lr 2.4000e-05 | norm: 13.1779 | dt: 1476.04ms | tok/sec: 2774.99\n",
            "step    2 | loss: 9.722557 | lr 3.6000e-05 | norm: 8.8818 | dt: 1476.24ms | tok/sec: 2774.61\n",
            "step    3 | loss: 9.448235 | lr 4.8000e-05 | norm: 6.0001 | dt: 1477.49ms | tok/sec: 2772.26\n",
            "step    4 | loss: 9.083000 | lr 6.0000e-05 | norm: 5.8405 | dt: 1488.10ms | tok/sec: 2752.51\n",
            "step    5 | loss: 8.929291 | lr 7.2000e-05 | norm: 5.8820 | dt: 1484.85ms | tok/sec: 2758.52\n",
            "step    6 | loss: 8.496487 | lr 8.4000e-05 | norm: 9.2229 | dt: 1491.29ms | tok/sec: 2746.62\n",
            "step    7 | loss: 8.453780 | lr 9.6000e-05 | norm: 6.0118 | dt: 1499.22ms | tok/sec: 2732.08\n",
            "step    8 | loss: 8.393055 | lr 1.0800e-04 | norm: 7.6930 | dt: 1497.09ms | tok/sec: 2735.98\n",
            "step    9 | loss: 8.037750 | lr 1.2000e-04 | norm: 24.5127 | dt: 1497.70ms | tok/sec: 2734.86\n",
            "step   10 | loss: 7.908815 | lr 1.3200e-04 | norm: 4.2781 | dt: 1497.90ms | tok/sec: 2734.49\n",
            "step   11 | loss: 7.848441 | lr 1.4400e-04 | norm: 3.3454 | dt: 1509.76ms | tok/sec: 2713.01\n",
            "step   12 | loss: 7.968532 | lr 1.5600e-04 | norm: 3.1114 | dt: 1508.06ms | tok/sec: 2716.07\n",
            "step   13 | loss: 7.709227 | lr 1.6800e-04 | norm: 3.0724 | dt: 1512.93ms | tok/sec: 2707.32\n",
            "step   14 | loss: 7.719003 | lr 1.8000e-04 | norm: 4.6564 | dt: 1514.62ms | tok/sec: 2704.31\n",
            "step   15 | loss: 7.404949 | lr 1.9200e-04 | norm: 2.5435 | dt: 1519.80ms | tok/sec: 2695.09\n",
            "step   16 | loss: 7.097351 | lr 2.0400e-04 | norm: 2.2446 | dt: 1520.56ms | tok/sec: 2693.74\n",
            "step   17 | loss: 7.138934 | lr 2.1600e-04 | norm: 3.8126 | dt: 1526.68ms | tok/sec: 2682.95\n",
            "step   18 | loss: 6.989036 | lr 2.2800e-04 | norm: 1.9921 | dt: 1526.06ms | tok/sec: 2684.03\n",
            "step   19 | loss: 6.608828 | lr 2.4000e-04 | norm: 2.2480 | dt: 1531.54ms | tok/sec: 2674.43\n",
            "step   20 | loss: 6.441331 | lr 2.5200e-04 | norm: 2.2713 | dt: 1540.12ms | tok/sec: 2659.54\n",
            "step   21 | loss: 6.468199 | lr 2.6400e-04 | norm: 2.3632 | dt: 1537.87ms | tok/sec: 2663.42\n",
            "step   22 | loss: 5.912052 | lr 2.7600e-04 | norm: 3.0164 | dt: 1538.37ms | tok/sec: 2662.56\n",
            "step   23 | loss: 5.881364 | lr 2.8800e-04 | norm: 2.2172 | dt: 1547.42ms | tok/sec: 2646.98\n",
            "step   24 | loss: 5.803995 | lr 3.0000e-04 | norm: 2.0124 | dt: 1555.40ms | tok/sec: 2633.41\n",
            "step   25 | loss: 5.655549 | lr 3.1200e-04 | norm: 1.8720 | dt: 1561.61ms | tok/sec: 2622.94\n",
            "step   26 | loss: 5.723174 | lr 3.2400e-04 | norm: 2.3733 | dt: 1562.15ms | tok/sec: 2622.03\n",
            "step   27 | loss: 5.261079 | lr 3.3600e-04 | norm: 1.8465 | dt: 1558.46ms | tok/sec: 2628.23\n",
            "step   28 | loss: 5.222624 | lr 3.4800e-04 | norm: 2.6329 | dt: 1573.22ms | tok/sec: 2603.58\n",
            "step   29 | loss: 5.228714 | lr 3.6000e-04 | norm: 1.7653 | dt: 1576.09ms | tok/sec: 2598.84\n",
            "step   30 | loss: 5.150427 | lr 3.7200e-04 | norm: 1.3422 | dt: 1576.81ms | tok/sec: 2597.66\n",
            "step   31 | loss: 5.135645 | lr 3.8400e-04 | norm: 1.1153 | dt: 1576.64ms | tok/sec: 2597.93\n",
            "step   32 | loss: 5.039181 | lr 3.9600e-04 | norm: 1.5702 | dt: 1592.92ms | tok/sec: 2571.38\n",
            "step   33 | loss: 4.882133 | lr 4.0800e-04 | norm: 1.6953 | dt: 1598.02ms | tok/sec: 2563.18\n",
            "step   34 | loss: 4.895582 | lr 4.2000e-04 | norm: 1.4159 | dt: 1596.66ms | tok/sec: 2565.36\n",
            "step   35 | loss: 4.933684 | lr 4.3200e-04 | norm: 1.9219 | dt: 1597.25ms | tok/sec: 2564.41\n",
            "step   36 | loss: 4.839963 | lr 4.4400e-04 | norm: 1.5496 | dt: 1601.09ms | tok/sec: 2558.25\n",
            "step   37 | loss: 4.686057 | lr 4.5600e-04 | norm: 1.4934 | dt: 1610.00ms | tok/sec: 2544.10\n",
            "step   38 | loss: 4.998967 | lr 4.6800e-04 | norm: 1.6392 | dt: 1606.14ms | tok/sec: 2550.22\n",
            "step   39 | loss: 4.694540 | lr 4.8000e-04 | norm: 1.6260 | dt: 1612.10ms | tok/sec: 2540.79\n",
            "step   40 | loss: 4.871940 | lr 4.9200e-04 | norm: 1.4127 | dt: 1617.22ms | tok/sec: 2532.74\n",
            "step   41 | loss: 4.723675 | lr 5.0400e-04 | norm: 2.8376 | dt: 1618.91ms | tok/sec: 2530.09\n",
            "step   42 | loss: 4.749290 | lr 5.1600e-04 | norm: 1.8296 | dt: 1618.93ms | tok/sec: 2530.06\n",
            "step   43 | loss: 4.732337 | lr 5.2800e-04 | norm: 1.7963 | dt: 1634.80ms | tok/sec: 2505.50\n",
            "step   44 | loss: 4.742101 | lr 5.4000e-04 | norm: 1.6539 | dt: 1638.73ms | tok/sec: 2499.50\n",
            "step   45 | loss: 4.649652 | lr 5.5200e-04 | norm: 2.1438 | dt: 1644.81ms | tok/sec: 2490.26\n",
            "step   46 | loss: 4.309796 | lr 5.6400e-04 | norm: 3.8676 | dt: 1660.68ms | tok/sec: 2466.46\n",
            "step   47 | loss: 4.475117 | lr 5.7600e-04 | norm: 1.9567 | dt: 1654.19ms | tok/sec: 2476.14\n",
            "step   48 | loss: 4.484111 | lr 5.8800e-04 | norm: 1.5218 | dt: 1660.40ms | tok/sec: 2466.88\n",
            "step   49 | loss: 4.654099 | lr 6.0000e-04 | norm: 2.2158 | dt: 1660.93ms | tok/sec: 2466.08\n",
            "step   50 | loss: 4.519504 | lr 6.0000e-04 | norm: 2.4872 | dt: 1670.36ms | tok/sec: 2452.17\n",
            "step   51 | loss: 4.557225 | lr 5.9999e-04 | norm: 1.7073 | dt: 1671.04ms | tok/sec: 2451.16\n",
            "step   52 | loss: 4.297134 | lr 5.9997e-04 | norm: 2.1079 | dt: 1674.36ms | tok/sec: 2446.30\n",
            "step   53 | loss: 4.338378 | lr 5.9994e-04 | norm: 1.6201 | dt: 1687.99ms | tok/sec: 2426.55\n",
            "step   54 | loss: 4.658728 | lr 5.9989e-04 | norm: 2.4125 | dt: 1692.87ms | tok/sec: 2419.56\n",
            "step   55 | loss: 4.193673 | lr 5.9984e-04 | norm: 2.0652 | dt: 1700.17ms | tok/sec: 2409.17\n",
            "step   56 | loss: 4.335505 | lr 5.9976e-04 | norm: 1.8520 | dt: 1702.18ms | tok/sec: 2406.33\n",
            "step   57 | loss: 4.390224 | lr 5.9968e-04 | norm: 1.5454 | dt: 1709.25ms | tok/sec: 2396.37\n",
            "step   58 | loss: 3.809945 | lr 5.9958e-04 | norm: 1.5868 | dt: 1723.06ms | tok/sec: 2377.16\n",
            "step   59 | loss: 4.342382 | lr 5.9947e-04 | norm: 1.7281 | dt: 1722.89ms | tok/sec: 2377.40\n",
            "step   60 | loss: 4.194407 | lr 5.9934e-04 | norm: 1.6476 | dt: 1723.30ms | tok/sec: 2376.83\n",
            "step   61 | loss: 4.134027 | lr 5.9920e-04 | norm: 1.7001 | dt: 1735.08ms | tok/sec: 2360.69\n",
            "step   62 | loss: 4.118028 | lr 5.9905e-04 | norm: 1.5609 | dt: 1731.34ms | tok/sec: 2365.80\n",
            "step   63 | loss: 4.398827 | lr 5.9889e-04 | norm: 1.8788 | dt: 1735.30ms | tok/sec: 2360.40\n",
            "step   64 | loss: 4.264966 | lr 5.9871e-04 | norm: 1.2048 | dt: 1736.14ms | tok/sec: 2359.26\n",
            "step   65 | loss: 4.017577 | lr 5.9852e-04 | norm: 1.2872 | dt: 1734.56ms | tok/sec: 2361.40\n",
            "step   66 | loss: 4.043276 | lr 5.9832e-04 | norm: 1.5590 | dt: 1732.94ms | tok/sec: 2363.61\n",
            "step   67 | loss: 3.999002 | lr 5.9810e-04 | norm: 1.7210 | dt: 1734.24ms | tok/sec: 2361.84\n",
            "step   68 | loss: 4.093080 | lr 5.9787e-04 | norm: 1.2961 | dt: 1719.27ms | tok/sec: 2382.41\n",
            "step   69 | loss: 3.843511 | lr 5.9763e-04 | norm: 1.8313 | dt: 1721.94ms | tok/sec: 2378.71\n",
            "step   70 | loss: 4.030642 | lr 5.9737e-04 | norm: 1.3673 | dt: 1709.58ms | tok/sec: 2395.90\n",
            "step   71 | loss: 4.071179 | lr 5.9710e-04 | norm: 1.3339 | dt: 1705.02ms | tok/sec: 2402.31\n",
            "step   72 | loss: 3.920526 | lr 5.9682e-04 | norm: 1.5691 | dt: 1694.64ms | tok/sec: 2417.03\n",
            "step   73 | loss: 3.832439 | lr 5.9653e-04 | norm: 1.2464 | dt: 1694.85ms | tok/sec: 2416.73\n",
            "step   74 | loss: 3.890844 | lr 5.9622e-04 | norm: 1.2313 | dt: 1701.43ms | tok/sec: 2407.38\n",
            "step   75 | loss: 4.016653 | lr 5.9590e-04 | norm: 1.7918 | dt: 1684.00ms | tok/sec: 2432.31\n",
            "step   76 | loss: 4.008876 | lr 5.9556e-04 | norm: 1.2313 | dt: 1679.80ms | tok/sec: 2438.38\n",
            "step   77 | loss: 4.152074 | lr 5.9522e-04 | norm: 1.7169 | dt: 1680.36ms | tok/sec: 2437.57\n",
            "step   78 | loss: 3.744499 | lr 5.9486e-04 | norm: 1.4385 | dt: 1677.05ms | tok/sec: 2442.38\n",
            "step   79 | loss: 3.958963 | lr 5.9449e-04 | norm: 1.3303 | dt: 1675.31ms | tok/sec: 2444.92\n",
            "step   80 | loss: 4.082405 | lr 5.9410e-04 | norm: 1.0191 | dt: 1672.17ms | tok/sec: 2449.52\n",
            "step   81 | loss: 3.830083 | lr 5.9370e-04 | norm: 1.4926 | dt: 1659.56ms | tok/sec: 2468.13\n",
            "step   82 | loss: 3.870720 | lr 5.9329e-04 | norm: 1.5387 | dt: 1672.63ms | tok/sec: 2448.84\n",
            "step   83 | loss: 4.194841 | lr 5.9287e-04 | norm: 1.3392 | dt: 1657.39ms | tok/sec: 2471.35\n",
            "step   84 | loss: 3.888192 | lr 5.9243e-04 | norm: 1.2689 | dt: 1659.53ms | tok/sec: 2468.17\n",
            "step   85 | loss: 3.867828 | lr 5.9198e-04 | norm: 1.3853 | dt: 1652.03ms | tok/sec: 2479.38\n",
            "step   86 | loss: 3.737628 | lr 5.9152e-04 | norm: 1.4312 | dt: 1655.41ms | tok/sec: 2474.31\n",
            "step   87 | loss: 3.824161 | lr 5.9104e-04 | norm: 1.7912 | dt: 1656.80ms | tok/sec: 2472.24\n",
            "step   88 | loss: 3.496870 | lr 5.9055e-04 | norm: 1.2744 | dt: 1656.74ms | tok/sec: 2472.33\n",
            "step   89 | loss: 3.560991 | lr 5.9005e-04 | norm: 1.3271 | dt: 1655.45ms | tok/sec: 2474.26\n",
            "step   90 | loss: 3.786990 | lr 5.8954e-04 | norm: 1.2950 | dt: 1654.20ms | tok/sec: 2476.13\n",
            "step   91 | loss: 3.742378 | lr 5.8901e-04 | norm: 1.3136 | dt: 1649.96ms | tok/sec: 2482.49\n",
            "step   92 | loss: 3.439579 | lr 5.8848e-04 | norm: 1.4156 | dt: 1655.14ms | tok/sec: 2474.71\n",
            "step   93 | loss: 3.856834 | lr 5.8793e-04 | norm: 1.1812 | dt: 1658.77ms | tok/sec: 2469.29\n",
            "step   94 | loss: 3.908206 | lr 5.8736e-04 | norm: 1.3252 | dt: 1659.45ms | tok/sec: 2468.29\n",
            "step   95 | loss: 3.820768 | lr 5.8679e-04 | norm: 1.1660 | dt: 1656.33ms | tok/sec: 2472.94\n",
            "step   96 | loss: 3.768708 | lr 5.8620e-04 | norm: 1.2628 | dt: 1659.85ms | tok/sec: 2467.70\n",
            "step   97 | loss: 3.586573 | lr 5.8560e-04 | norm: 1.4238 | dt: 1656.68ms | tok/sec: 2472.42\n",
            "step   98 | loss: 3.767621 | lr 5.8498e-04 | norm: 1.2384 | dt: 1661.55ms | tok/sec: 2465.16\n",
            "step   99 | loss: 3.730107 | lr 5.8436e-04 | norm: 1.7957 | dt: 1659.88ms | tok/sec: 2467.65\n",
            "step  100 | loss: 3.588915 | lr 5.8372e-04 | norm: 1.0358 | dt: 1656.34ms | tok/sec: 2472.92\n",
            "step  101 | loss: 3.469483 | lr 5.8307e-04 | norm: 1.1982 | dt: 1658.74ms | tok/sec: 2469.35\n",
            "step  102 | loss: 3.341557 | lr 5.8240e-04 | norm: 1.5749 | dt: 1657.65ms | tok/sec: 2470.98\n",
            "step  103 | loss: 3.391477 | lr 5.8173e-04 | norm: 1.0726 | dt: 1657.77ms | tok/sec: 2470.79\n",
            "step  104 | loss: 3.440986 | lr 5.8104e-04 | norm: 1.4617 | dt: 1670.74ms | tok/sec: 2451.61\n",
            "step  105 | loss: 3.641557 | lr 5.8034e-04 | norm: 1.1261 | dt: 1668.67ms | tok/sec: 2454.64\n",
            "step  106 | loss: 3.311445 | lr 5.7963e-04 | norm: 1.2568 | dt: 1668.29ms | tok/sec: 2455.21\n",
            "step  107 | loss: 3.665374 | lr 5.7890e-04 | norm: 1.1721 | dt: 1674.79ms | tok/sec: 2445.68\n",
            "step  108 | loss: 3.577856 | lr 5.7817e-04 | norm: 1.2258 | dt: 1673.02ms | tok/sec: 2448.27\n",
            "step  109 | loss: 3.468878 | lr 5.7742e-04 | norm: 0.9980 | dt: 1676.15ms | tok/sec: 2443.70\n",
            "step  110 | loss: 3.251907 | lr 5.7666e-04 | norm: 1.5701 | dt: 1681.74ms | tok/sec: 2435.57\n",
            "step  111 | loss: 3.619427 | lr 5.7588e-04 | norm: 1.1341 | dt: 1677.36ms | tok/sec: 2441.93\n",
            "step  112 | loss: 3.476486 | lr 5.7510e-04 | norm: 1.3654 | dt: 1681.16ms | tok/sec: 2436.41\n",
            "step  113 | loss: 3.210561 | lr 5.7430e-04 | norm: 1.0326 | dt: 1688.02ms | tok/sec: 2426.51\n",
            "step  114 | loss: 3.616884 | lr 5.7349e-04 | norm: 1.7689 | dt: 1683.30ms | tok/sec: 2433.31\n",
            "step  115 | loss: 3.216005 | lr 5.7267e-04 | norm: 1.6288 | dt: 1693.80ms | tok/sec: 2418.23\n",
            "step  116 | loss: 3.737504 | lr 5.7184e-04 | norm: 1.3606 | dt: 1690.77ms | tok/sec: 2422.56\n",
            "step  117 | loss: 3.297987 | lr 5.7100e-04 | norm: 1.4978 | dt: 1689.31ms | tok/sec: 2424.66\n",
            "step  118 | loss: 3.512723 | lr 5.7014e-04 | norm: 1.4511 | dt: 1687.81ms | tok/sec: 2426.81\n",
            "step  119 | loss: 3.434142 | lr 5.6927e-04 | norm: 1.6585 | dt: 1687.14ms | tok/sec: 2427.77\n",
            "step  120 | loss: 3.460769 | lr 5.6840e-04 | norm: 1.2861 | dt: 1683.99ms | tok/sec: 2432.31\n",
            "step  121 | loss: 3.483319 | lr 5.6751e-04 | norm: 1.4880 | dt: 1692.83ms | tok/sec: 2419.62\n",
            "step  122 | loss: 3.317451 | lr 5.6660e-04 | norm: 1.1531 | dt: 1686.51ms | tok/sec: 2428.68\n",
            "step  123 | loss: 3.311185 | lr 5.6569e-04 | norm: 1.3287 | dt: 1686.26ms | tok/sec: 2429.05\n",
            "step  124 | loss: 3.211890 | lr 5.6476e-04 | norm: 1.0333 | dt: 1680.75ms | tok/sec: 2437.01\n",
            "step  125 | loss: 3.503842 | lr 5.6383e-04 | norm: 1.3850 | dt: 1681.87ms | tok/sec: 2435.39\n",
            "step  126 | loss: 3.189733 | lr 5.6288e-04 | norm: 1.4353 | dt: 1685.30ms | tok/sec: 2430.43\n",
            "step  127 | loss: 3.626171 | lr 5.6192e-04 | norm: 1.5029 | dt: 1684.80ms | tok/sec: 2431.15\n",
            "step  128 | loss: 3.673798 | lr 5.6095e-04 | norm: 1.6068 | dt: 1676.73ms | tok/sec: 2442.85\n",
            "step  129 | loss: 3.452244 | lr 5.5997e-04 | norm: 1.3994 | dt: 1676.62ms | tok/sec: 2443.01\n",
            "step  130 | loss: 3.441355 | lr 5.5897e-04 | norm: 1.1184 | dt: 1679.35ms | tok/sec: 2439.04\n",
            "step  131 | loss: 3.247053 | lr 5.5797e-04 | norm: 1.4219 | dt: 1674.28ms | tok/sec: 2446.42\n",
            "step  132 | loss: 3.503526 | lr 5.5695e-04 | norm: 1.1133 | dt: 1672.11ms | tok/sec: 2449.59\n",
            "step  133 | loss: 3.338024 | lr 5.5593e-04 | norm: 1.3655 | dt: 1678.85ms | tok/sec: 2439.77\n",
            "step  134 | loss: 3.215827 | lr 5.5489e-04 | norm: 1.5089 | dt: 1676.35ms | tok/sec: 2443.40\n",
            "step  135 | loss: 3.269129 | lr 5.5384e-04 | norm: 1.3566 | dt: 1677.81ms | tok/sec: 2441.27\n",
            "step  136 | loss: 3.042380 | lr 5.5278e-04 | norm: 1.3149 | dt: 1678.16ms | tok/sec: 2440.76\n",
            "step  137 | loss: 3.024482 | lr 5.5171e-04 | norm: 1.0964 | dt: 1676.40ms | tok/sec: 2443.33\n",
            "step  138 | loss: 3.160913 | lr 5.5063e-04 | norm: 1.3484 | dt: 1680.17ms | tok/sec: 2437.85\n",
            "step  139 | loss: 3.077282 | lr 5.4954e-04 | norm: 1.0320 | dt: 1672.97ms | tok/sec: 2448.34\n",
            "step  140 | loss: 3.265605 | lr 5.4843e-04 | norm: 1.2528 | dt: 1677.21ms | tok/sec: 2442.16\n",
            "step  141 | loss: 3.203042 | lr 5.4732e-04 | norm: 1.0351 | dt: 1675.66ms | tok/sec: 2444.41\n",
            "step  142 | loss: 3.085899 | lr 5.4620e-04 | norm: 1.1203 | dt: 1667.26ms | tok/sec: 2456.72\n",
            "step  143 | loss: 3.236900 | lr 5.4506e-04 | norm: 1.4000 | dt: 1668.94ms | tok/sec: 2454.25\n",
            "step  144 | loss: 3.266865 | lr 5.4392e-04 | norm: 1.9251 | dt: 1671.04ms | tok/sec: 2451.17\n",
            "step  145 | loss: 3.090852 | lr 5.4276e-04 | norm: 0.9979 | dt: 1665.62ms | tok/sec: 2459.15\n",
            "step  146 | loss: 3.051875 | lr 5.4160e-04 | norm: 1.2288 | dt: 1666.19ms | tok/sec: 2458.30\n",
            "step  147 | loss: 3.111306 | lr 5.4042e-04 | norm: 1.3660 | dt: 1664.62ms | tok/sec: 2460.62\n",
            "step  148 | loss: 3.092631 | lr 5.3924e-04 | norm: 1.0290 | dt: 1673.28ms | tok/sec: 2447.89\n",
            "step  149 | loss: 3.270474 | lr 5.3804e-04 | norm: 1.2272 | dt: 1678.86ms | tok/sec: 2439.75\n",
            "step  150 | loss: 2.828104 | lr 5.3683e-04 | norm: 1.1442 | dt: 1676.74ms | tok/sec: 2442.84\n",
            "step  151 | loss: 3.239142 | lr 5.3562e-04 | norm: 1.1496 | dt: 1675.33ms | tok/sec: 2444.89\n",
            "step  152 | loss: 2.887869 | lr 5.3439e-04 | norm: 1.6552 | dt: 1673.12ms | tok/sec: 2448.12\n",
            "step  153 | loss: 2.753724 | lr 5.3315e-04 | norm: 1.4493 | dt: 1662.69ms | tok/sec: 2463.48\n",
            "step  154 | loss: 3.019875 | lr 5.3191e-04 | norm: 1.7497 | dt: 1673.24ms | tok/sec: 2447.94\n",
            "step  155 | loss: 3.212679 | lr 5.3065e-04 | norm: 1.1784 | dt: 1672.21ms | tok/sec: 2449.45\n",
            "step  156 | loss: 2.918631 | lr 5.2938e-04 | norm: 1.2137 | dt: 1662.82ms | tok/sec: 2463.28\n",
            "step  157 | loss: 3.078415 | lr 5.2811e-04 | norm: 1.1244 | dt: 1670.67ms | tok/sec: 2451.71\n",
            "step  158 | loss: 3.142013 | lr 5.2682e-04 | norm: 1.2422 | dt: 1679.15ms | tok/sec: 2439.33\n",
            "step  159 | loss: 3.062937 | lr 5.2553e-04 | norm: 1.1693 | dt: 1671.66ms | tok/sec: 2450.26\n",
            "step  160 | loss: 3.145394 | lr 5.2422e-04 | norm: 1.3493 | dt: 1677.79ms | tok/sec: 2441.31\n",
            "step  161 | loss: 3.122278 | lr 5.2291e-04 | norm: 1.2190 | dt: 1667.57ms | tok/sec: 2456.27\n",
            "step  162 | loss: 2.747259 | lr 5.2158e-04 | norm: 1.1126 | dt: 1671.60ms | tok/sec: 2450.35\n",
            "step  163 | loss: 2.984202 | lr 5.2025e-04 | norm: 1.0987 | dt: 1668.15ms | tok/sec: 2455.41\n",
            "step  164 | loss: 2.682400 | lr 5.1891e-04 | norm: 1.3281 | dt: 1662.81ms | tok/sec: 2463.29\n",
            "step  165 | loss: 3.029268 | lr 5.1756e-04 | norm: 1.1422 | dt: 1669.25ms | tok/sec: 2453.79\n",
            "step  166 | loss: 2.872913 | lr 5.1620e-04 | norm: 1.0483 | dt: 1675.91ms | tok/sec: 2444.05\n",
            "step  167 | loss: 2.830352 | lr 5.1483e-04 | norm: 1.1629 | dt: 1672.02ms | tok/sec: 2449.74\n",
            "step  168 | loss: 3.211479 | lr 5.1345e-04 | norm: 1.2159 | dt: 1671.15ms | tok/sec: 2451.01\n",
            "step  169 | loss: 3.113356 | lr 5.1206e-04 | norm: 1.1819 | dt: 1676.16ms | tok/sec: 2443.68\n",
            "step  170 | loss: 2.920963 | lr 5.1067e-04 | norm: 1.2274 | dt: 1669.40ms | tok/sec: 2453.57\n",
            "step  171 | loss: 2.743137 | lr 5.0926e-04 | norm: 1.3250 | dt: 1674.28ms | tok/sec: 2446.43\n",
            "step  172 | loss: 2.763118 | lr 5.0785e-04 | norm: 1.0253 | dt: 1676.96ms | tok/sec: 2442.52\n",
            "step  173 | loss: 3.407274 | lr 5.0642e-04 | norm: 0.9726 | dt: 1673.17ms | tok/sec: 2448.05\n",
            "step  174 | loss: 2.893028 | lr 5.0499e-04 | norm: 1.2397 | dt: 1672.00ms | tok/sec: 2449.76\n",
            "step  175 | loss: 3.126557 | lr 5.0355e-04 | norm: 1.1139 | dt: 1672.92ms | tok/sec: 2448.41\n",
            "step  176 | loss: 2.948172 | lr 5.0210e-04 | norm: 1.0953 | dt: 1674.39ms | tok/sec: 2446.26\n",
            "step  177 | loss: 2.720055 | lr 5.0065e-04 | norm: 1.2729 | dt: 1683.77ms | tok/sec: 2432.64\n",
            "step  178 | loss: 3.030911 | lr 4.9918e-04 | norm: 1.3207 | dt: 1665.63ms | tok/sec: 2459.12\n",
            "step  179 | loss: 2.607360 | lr 4.9771e-04 | norm: 1.5830 | dt: 1676.05ms | tok/sec: 2443.85\n",
            "step  180 | loss: 2.981052 | lr 4.9623e-04 | norm: 1.2558 | dt: 1677.15ms | tok/sec: 2442.23\n",
            "step  181 | loss: 2.934464 | lr 4.9474e-04 | norm: 1.3021 | dt: 1675.26ms | tok/sec: 2444.99\n",
            "step  182 | loss: 2.643539 | lr 4.9324e-04 | norm: 1.1577 | dt: 1676.08ms | tok/sec: 2443.79\n",
            "step  183 | loss: 2.561413 | lr 4.9174e-04 | norm: 1.0700 | dt: 1682.12ms | tok/sec: 2435.03\n",
            "step  184 | loss: 2.854256 | lr 4.9022e-04 | norm: 1.3068 | dt: 1682.60ms | tok/sec: 2434.33\n",
            "step  185 | loss: 2.684810 | lr 4.8870e-04 | norm: 1.3620 | dt: 1671.13ms | tok/sec: 2451.04\n",
            "step  186 | loss: 2.865910 | lr 4.8717e-04 | norm: 1.3625 | dt: 1679.11ms | tok/sec: 2439.39\n",
            "step  187 | loss: 2.797368 | lr 4.8564e-04 | norm: 1.1285 | dt: 1674.16ms | tok/sec: 2446.60\n",
            "step  188 | loss: 2.475828 | lr 4.8409e-04 | norm: 1.1120 | dt: 1674.73ms | tok/sec: 2445.77\n",
            "step  189 | loss: 2.854197 | lr 4.8254e-04 | norm: 1.2455 | dt: 1671.28ms | tok/sec: 2450.82\n",
            "step  190 | loss: 2.717691 | lr 4.8098e-04 | norm: 1.2912 | dt: 1679.92ms | tok/sec: 2438.22\n",
            "step  191 | loss: 3.082420 | lr 4.7942e-04 | norm: 1.7128 | dt: 1676.29ms | tok/sec: 2443.50\n",
            "step  192 | loss: 2.672218 | lr 4.7784e-04 | norm: 1.3091 | dt: 1681.22ms | tok/sec: 2436.33\n",
            "step  193 | loss: 2.692061 | lr 4.7626e-04 | norm: 1.2419 | dt: 1676.03ms | tok/sec: 2443.88\n",
            "step  194 | loss: 2.412967 | lr 4.7467e-04 | norm: 1.6347 | dt: 1671.09ms | tok/sec: 2451.09\n",
            "step  195 | loss: 2.898108 | lr 4.7308e-04 | norm: 2.0365 | dt: 1672.57ms | tok/sec: 2448.92\n",
            "step  196 | loss: 2.539526 | lr 4.7148e-04 | norm: 1.4269 | dt: 1681.27ms | tok/sec: 2436.25\n",
            "step  197 | loss: 2.747336 | lr 4.6987e-04 | norm: 1.2684 | dt: 1677.79ms | tok/sec: 2441.30\n",
            "step  198 | loss: 2.665217 | lr 4.6825e-04 | norm: 1.3612 | dt: 1683.03ms | tok/sec: 2433.70\n",
            "step  199 | loss: 2.784886 | lr 4.6663e-04 | norm: 1.4458 | dt: 1680.32ms | tok/sec: 2437.63\n",
            "step  200 | loss: 2.948347 | lr 4.6500e-04 | norm: 1.1448 | dt: 1669.45ms | tok/sec: 2453.51\n",
            "step  201 | loss: 2.841038 | lr 4.6336e-04 | norm: 1.5936 | dt: 1678.11ms | tok/sec: 2440.84\n",
            "step  202 | loss: 2.809943 | lr 4.6172e-04 | norm: 1.1205 | dt: 1666.90ms | tok/sec: 2457.25\n",
            "step  203 | loss: 2.798070 | lr 4.6007e-04 | norm: 1.2244 | dt: 1677.33ms | tok/sec: 2441.98\n",
            "step  204 | loss: 2.883968 | lr 4.5842e-04 | norm: 1.2364 | dt: 1675.51ms | tok/sec: 2444.63\n",
            "step  205 | loss: 2.758349 | lr 4.5676e-04 | norm: 1.1889 | dt: 1682.74ms | tok/sec: 2434.13\n",
            "step  206 | loss: 2.656917 | lr 4.5509e-04 | norm: 1.6029 | dt: 1673.05ms | tok/sec: 2448.22\n",
            "step  207 | loss: 2.621903 | lr 4.5342e-04 | norm: 1.4563 | dt: 1676.69ms | tok/sec: 2442.91\n",
            "step  208 | loss: 2.420525 | lr 4.5174e-04 | norm: 1.2099 | dt: 1681.01ms | tok/sec: 2436.63\n",
            "step  209 | loss: 2.494337 | lr 4.5005e-04 | norm: 1.5438 | dt: 1684.08ms | tok/sec: 2432.19\n",
            "step  210 | loss: 2.568618 | lr 4.4836e-04 | norm: 1.3809 | dt: 1677.63ms | tok/sec: 2441.53\n",
            "step  211 | loss: 2.687308 | lr 4.4666e-04 | norm: 1.5308 | dt: 1674.13ms | tok/sec: 2446.64\n",
            "step  212 | loss: 2.664806 | lr 4.4496e-04 | norm: 1.3376 | dt: 1677.22ms | tok/sec: 2442.13\n",
            "step  213 | loss: 2.144941 | lr 4.4325e-04 | norm: 1.1342 | dt: 1675.88ms | tok/sec: 2444.10\n",
            "step  214 | loss: 2.328884 | lr 4.4154e-04 | norm: 1.3068 | dt: 1680.24ms | tok/sec: 2437.75\n",
            "step  215 | loss: 2.644977 | lr 4.3982e-04 | norm: 1.4072 | dt: 1677.24ms | tok/sec: 2442.10\n",
            "step  216 | loss: 2.515424 | lr 4.3809e-04 | norm: 1.0277 | dt: 1678.70ms | tok/sec: 2439.98\n",
            "step  217 | loss: 2.487322 | lr 4.3636e-04 | norm: 1.5352 | dt: 1677.80ms | tok/sec: 2441.29\n",
            "step  218 | loss: 2.641198 | lr 4.3463e-04 | norm: 1.3748 | dt: 1679.80ms | tok/sec: 2438.38\n",
            "step  219 | loss: 2.819960 | lr 4.3289e-04 | norm: 1.3895 | dt: 1675.96ms | tok/sec: 2443.97\n",
            "step  220 | loss: 2.336278 | lr 4.3114e-04 | norm: 1.2446 | dt: 1674.09ms | tok/sec: 2446.70\n",
            "step  221 | loss: 2.617258 | lr 4.2939e-04 | norm: 1.3642 | dt: 1673.96ms | tok/sec: 2446.89\n",
            "step  222 | loss: 2.326418 | lr 4.2764e-04 | norm: 1.1295 | dt: 1671.49ms | tok/sec: 2450.50\n",
            "step  223 | loss: 2.291808 | lr 4.2588e-04 | norm: 1.0913 | dt: 1680.22ms | tok/sec: 2437.78\n",
            "step  224 | loss: 2.150715 | lr 4.2411e-04 | norm: 1.0669 | dt: 1680.41ms | tok/sec: 2437.50\n",
            "step  225 | loss: 2.560931 | lr 4.2235e-04 | norm: 1.2522 | dt: 1683.79ms | tok/sec: 2432.61\n",
            "step  226 | loss: 2.272482 | lr 4.2057e-04 | norm: 1.0916 | dt: 1678.06ms | tok/sec: 2440.91\n",
            "step  227 | loss: 2.432564 | lr 4.1879e-04 | norm: 1.1423 | dt: 1681.11ms | tok/sec: 2436.49\n",
            "step  228 | loss: 2.525895 | lr 4.1701e-04 | norm: 1.2198 | dt: 1670.71ms | tok/sec: 2451.65\n",
            "step  229 | loss: 2.402712 | lr 4.1523e-04 | norm: 1.1453 | dt: 1680.94ms | tok/sec: 2436.73\n",
            "step  230 | loss: 2.705953 | lr 4.1343e-04 | norm: 1.3089 | dt: 1682.34ms | tok/sec: 2434.71\n",
            "step  231 | loss: 2.356493 | lr 4.1164e-04 | norm: 1.4291 | dt: 1678.08ms | tok/sec: 2440.88\n",
            "step  232 | loss: 2.435394 | lr 4.0984e-04 | norm: 1.4334 | dt: 1679.56ms | tok/sec: 2438.73\n",
            "step  233 | loss: 2.187825 | lr 4.0804e-04 | norm: 1.3080 | dt: 1675.90ms | tok/sec: 2444.06\n",
            "step  234 | loss: 2.261450 | lr 4.0623e-04 | norm: 1.2307 | dt: 1680.91ms | tok/sec: 2436.78\n",
            "step  235 | loss: 2.602840 | lr 4.0442e-04 | norm: 1.6774 | dt: 1674.47ms | tok/sec: 2446.15\n",
            "step  236 | loss: 2.398436 | lr 4.0261e-04 | norm: 1.4657 | dt: 1672.60ms | tok/sec: 2448.88\n",
            "step  237 | loss: 2.422107 | lr 4.0079e-04 | norm: 1.3259 | dt: 1683.73ms | tok/sec: 2432.70\n",
            "step  238 | loss: 2.353002 | lr 3.9897e-04 | norm: 1.6043 | dt: 1670.71ms | tok/sec: 2451.65\n",
            "step  239 | loss: 2.316969 | lr 3.9715e-04 | norm: 1.5736 | dt: 1677.67ms | tok/sec: 2441.49\n",
            "step  240 | loss: 2.345347 | lr 3.9532e-04 | norm: 1.8660 | dt: 1682.86ms | tok/sec: 2433.95\n",
            "step  241 | loss: 2.508341 | lr 3.9349e-04 | norm: 1.3072 | dt: 1676.33ms | tok/sec: 2443.43\n",
            "step  242 | loss: 2.473391 | lr 3.9165e-04 | norm: 1.2227 | dt: 1678.97ms | tok/sec: 2439.59\n",
            "step  243 | loss: 2.150867 | lr 3.8982e-04 | norm: 1.2592 | dt: 1684.69ms | tok/sec: 2431.30\n",
            "step  244 | loss: 2.349644 | lr 3.8798e-04 | norm: 1.1740 | dt: 1676.99ms | tok/sec: 2442.47\n",
            "step  245 | loss: 2.384147 | lr 3.8614e-04 | norm: 1.2403 | dt: 1678.92ms | tok/sec: 2439.66\n",
            "step  246 | loss: 2.179541 | lr 3.8429e-04 | norm: 1.3751 | dt: 1675.91ms | tok/sec: 2444.04\n",
            "step  247 | loss: 2.308445 | lr 3.8244e-04 | norm: 1.5709 | dt: 1690.83ms | tok/sec: 2422.48\n",
            "step  248 | loss: 2.199338 | lr 3.8059e-04 | norm: 1.6314 | dt: 1675.12ms | tok/sec: 2445.20\n",
            "step  249 | loss: 2.142970 | lr 3.7874e-04 | norm: 1.5017 | dt: 1679.54ms | tok/sec: 2438.76\n",
            "step  250 | loss: 2.076366 | lr 3.7689e-04 | norm: 1.5618 | dt: 1684.86ms | tok/sec: 2431.06\n",
            "step  251 | loss: 2.221214 | lr 3.7503e-04 | norm: 1.2031 | dt: 1674.16ms | tok/sec: 2446.61\n",
            "step  252 | loss: 2.369893 | lr 3.7317e-04 | norm: 1.3983 | dt: 1686.63ms | tok/sec: 2428.52\n",
            "step  253 | loss: 2.290576 | lr 3.7131e-04 | norm: 1.4814 | dt: 1676.20ms | tok/sec: 2443.63\n",
            "step  254 | loss: 2.281464 | lr 3.6944e-04 | norm: 1.4231 | dt: 1675.84ms | tok/sec: 2444.14\n",
            "step  255 | loss: 2.417538 | lr 3.6758e-04 | norm: 1.2810 | dt: 1678.58ms | tok/sec: 2440.15\n",
            "step  256 | loss: 2.121938 | lr 3.6571e-04 | norm: 1.3605 | dt: 1677.79ms | tok/sec: 2441.30\n",
            "step  257 | loss: 2.291906 | lr 3.6384e-04 | norm: 1.2872 | dt: 1679.81ms | tok/sec: 2438.37\n",
            "step  258 | loss: 2.206798 | lr 3.6197e-04 | norm: 1.3451 | dt: 1676.86ms | tok/sec: 2442.66\n",
            "step  259 | loss: 2.201957 | lr 3.6010e-04 | norm: 1.3055 | dt: 1679.39ms | tok/sec: 2438.98\n",
            "step  260 | loss: 2.081944 | lr 3.5822e-04 | norm: 1.1563 | dt: 1678.60ms | tok/sec: 2440.13\n",
            "step  261 | loss: 1.983642 | lr 3.5635e-04 | norm: 1.4717 | dt: 1673.32ms | tok/sec: 2447.82\n",
            "step  262 | loss: 2.109421 | lr 3.5447e-04 | norm: 1.3100 | dt: 1673.65ms | tok/sec: 2447.34\n",
            "step  263 | loss: 2.437372 | lr 3.5259e-04 | norm: 1.4642 | dt: 1679.20ms | tok/sec: 2439.26\n",
            "step  264 | loss: 2.220490 | lr 3.5071e-04 | norm: 1.2901 | dt: 1678.89ms | tok/sec: 2439.71\n",
            "step  265 | loss: 2.186837 | lr 3.4883e-04 | norm: 1.4688 | dt: 1685.68ms | tok/sec: 2429.88\n",
            "step  266 | loss: 2.347154 | lr 3.4695e-04 | norm: 1.3968 | dt: 1679.86ms | tok/sec: 2438.30\n",
            "step  267 | loss: 2.326182 | lr 3.4507e-04 | norm: 1.2928 | dt: 1681.84ms | tok/sec: 2435.43\n",
            "step  268 | loss: 2.153880 | lr 3.4319e-04 | norm: 1.1621 | dt: 1673.20ms | tok/sec: 2448.01\n",
            "step  269 | loss: 1.839926 | lr 3.4131e-04 | norm: 1.4813 | dt: 1673.77ms | tok/sec: 2447.16\n",
            "step  270 | loss: 2.081065 | lr 3.3942e-04 | norm: 1.3919 | dt: 1677.71ms | tok/sec: 2441.42\n",
            "step  271 | loss: 1.976332 | lr 3.3754e-04 | norm: 1.2014 | dt: 1672.16ms | tok/sec: 2449.53\n",
            "step  272 | loss: 1.904680 | lr 3.3565e-04 | norm: 1.5059 | dt: 1676.10ms | tok/sec: 2443.76\n",
            "step  273 | loss: 2.025209 | lr 3.3377e-04 | norm: 1.2786 | dt: 1676.17ms | tok/sec: 2443.67\n",
            "step  274 | loss: 2.168061 | lr 3.3188e-04 | norm: 1.3908 | dt: 1677.40ms | tok/sec: 2441.87\n",
            "step  275 | loss: 2.183666 | lr 3.3000e-04 | norm: 1.3293 | dt: 1675.91ms | tok/sec: 2444.04\n",
            "step  276 | loss: 2.154497 | lr 3.2812e-04 | norm: 1.3954 | dt: 1680.68ms | tok/sec: 2437.10\n",
            "step  277 | loss: 1.896069 | lr 3.2623e-04 | norm: 1.2482 | dt: 1672.95ms | tok/sec: 2448.37\n",
            "step  278 | loss: 1.904283 | lr 3.2435e-04 | norm: 1.5556 | dt: 1678.54ms | tok/sec: 2440.21\n",
            "step  279 | loss: 2.018294 | lr 3.2246e-04 | norm: 1.6078 | dt: 1674.61ms | tok/sec: 2445.94\n",
            "step  280 | loss: 1.959110 | lr 3.2058e-04 | norm: 1.3320 | dt: 1685.25ms | tok/sec: 2430.51\n",
            "step  281 | loss: 2.047387 | lr 3.1869e-04 | norm: 1.3255 | dt: 1681.96ms | tok/sec: 2435.26\n",
            "step  282 | loss: 2.274405 | lr 3.1681e-04 | norm: 1.7913 | dt: 1671.92ms | tok/sec: 2449.87\n",
            "step  283 | loss: 1.740581 | lr 3.1493e-04 | norm: 1.2254 | dt: 1670.69ms | tok/sec: 2451.68\n",
            "step  284 | loss: 1.921225 | lr 3.1305e-04 | norm: 1.4227 | dt: 1676.27ms | tok/sec: 2443.52\n",
            "step  285 | loss: 1.897992 | lr 3.1117e-04 | norm: 1.5659 | dt: 1677.63ms | tok/sec: 2441.54\n",
            "step  286 | loss: 1.982591 | lr 3.0929e-04 | norm: 1.4348 | dt: 1682.41ms | tok/sec: 2434.60\n",
            "step  287 | loss: 2.016887 | lr 3.0741e-04 | norm: 1.6248 | dt: 1676.46ms | tok/sec: 2443.25\n",
            "step  288 | loss: 1.861006 | lr 3.0553e-04 | norm: 1.4599 | dt: 1676.80ms | tok/sec: 2442.75\n",
            "step  289 | loss: 2.073422 | lr 3.0365e-04 | norm: 1.3887 | dt: 1678.05ms | tok/sec: 2440.93\n",
            "step  290 | loss: 2.047395 | lr 3.0178e-04 | norm: 1.3997 | dt: 1679.02ms | tok/sec: 2439.52\n",
            "step  291 | loss: 1.987693 | lr 2.9990e-04 | norm: 1.5109 | dt: 1675.81ms | tok/sec: 2444.19\n",
            "step  292 | loss: 1.880695 | lr 2.9803e-04 | norm: 1.2826 | dt: 1681.35ms | tok/sec: 2436.14\n",
            "step  293 | loss: 1.822655 | lr 2.9616e-04 | norm: 1.5410 | dt: 1672.83ms | tok/sec: 2448.55\n",
            "step  294 | loss: 1.969312 | lr 2.9429e-04 | norm: 1.6792 | dt: 1679.54ms | tok/sec: 2438.76\n",
            "step  295 | loss: 1.890389 | lr 2.9242e-04 | norm: 1.4681 | dt: 1677.69ms | tok/sec: 2441.45\n",
            "step  296 | loss: 1.957282 | lr 2.9056e-04 | norm: 1.4039 | dt: 1674.14ms | tok/sec: 2446.64\n",
            "step  297 | loss: 1.810302 | lr 2.8869e-04 | norm: 1.4002 | dt: 1679.11ms | tok/sec: 2439.38\n",
            "step  298 | loss: 1.901231 | lr 2.8683e-04 | norm: 1.4140 | dt: 1674.95ms | tok/sec: 2445.44\n",
            "step  299 | loss: 1.896393 | lr 2.8497e-04 | norm: 1.3517 | dt: 1679.41ms | tok/sec: 2438.94\n",
            "step  300 | loss: 1.805864 | lr 2.8311e-04 | norm: 1.1673 | dt: 1683.08ms | tok/sec: 2433.64\n",
            "step  301 | loss: 2.082191 | lr 2.8126e-04 | norm: 1.5690 | dt: 1675.88ms | tok/sec: 2444.08\n",
            "step  302 | loss: 1.891922 | lr 2.7941e-04 | norm: 1.5978 | dt: 1677.43ms | tok/sec: 2441.83\n",
            "step  303 | loss: 1.838027 | lr 2.7756e-04 | norm: 1.2358 | dt: 1679.26ms | tok/sec: 2439.17\n",
            "step  304 | loss: 1.690303 | lr 2.7571e-04 | norm: 1.5994 | dt: 1676.26ms | tok/sec: 2443.53\n",
            "step  305 | loss: 1.817018 | lr 2.7386e-04 | norm: 1.4653 | dt: 1674.24ms | tok/sec: 2446.48\n",
            "step  306 | loss: 1.975279 | lr 2.7202e-04 | norm: 1.4354 | dt: 1678.07ms | tok/sec: 2440.90\n",
            "step  307 | loss: 1.844744 | lr 2.7018e-04 | norm: 1.8919 | dt: 1680.39ms | tok/sec: 2437.53\n",
            "step  308 | loss: 1.802983 | lr 2.6835e-04 | norm: 1.2553 | dt: 1679.99ms | tok/sec: 2438.10\n",
            "step  309 | loss: 1.688968 | lr 2.6651e-04 | norm: 1.4768 | dt: 1687.65ms | tok/sec: 2427.04\n",
            "step  310 | loss: 1.722235 | lr 2.6468e-04 | norm: 1.5021 | dt: 1677.80ms | tok/sec: 2441.29\n",
            "step  311 | loss: 1.750841 | lr 2.6285e-04 | norm: 1.3982 | dt: 1688.52ms | tok/sec: 2425.79\n",
            "step  312 | loss: 1.812785 | lr 2.6103e-04 | norm: 1.3501 | dt: 1672.57ms | tok/sec: 2448.92\n",
            "step  313 | loss: 1.643128 | lr 2.5921e-04 | norm: 1.4639 | dt: 1684.20ms | tok/sec: 2432.02\n",
            "step  314 | loss: 1.683409 | lr 2.5739e-04 | norm: 1.3409 | dt: 1684.43ms | tok/sec: 2431.68\n",
            "step  315 | loss: 2.038145 | lr 2.5558e-04 | norm: 1.5682 | dt: 1678.09ms | tok/sec: 2440.86\n",
            "step  316 | loss: 1.674979 | lr 2.5377e-04 | norm: 1.2552 | dt: 1682.24ms | tok/sec: 2434.86\n",
            "step  317 | loss: 1.663463 | lr 2.5196e-04 | norm: 1.3042 | dt: 1679.11ms | tok/sec: 2439.39\n",
            "step  318 | loss: 1.614685 | lr 2.5016e-04 | norm: 1.4484 | dt: 1678.78ms | tok/sec: 2439.87\n",
            "step  319 | loss: 1.944615 | lr 2.4836e-04 | norm: 1.5183 | dt: 1678.57ms | tok/sec: 2440.17\n",
            "step  320 | loss: 1.639583 | lr 2.4657e-04 | norm: 1.4129 | dt: 1679.07ms | tok/sec: 2439.44\n",
            "step  321 | loss: 1.600632 | lr 2.4477e-04 | norm: 1.3951 | dt: 1675.80ms | tok/sec: 2444.20\n",
            "step  322 | loss: 1.774770 | lr 2.4299e-04 | norm: 1.1863 | dt: 1681.19ms | tok/sec: 2436.37\n",
            "step  323 | loss: 1.562040 | lr 2.4121e-04 | norm: 1.3845 | dt: 1685.39ms | tok/sec: 2430.29\n",
            "step  324 | loss: 1.625272 | lr 2.3943e-04 | norm: 1.4019 | dt: 1678.12ms | tok/sec: 2440.82\n",
            "step  325 | loss: 1.655259 | lr 2.3765e-04 | norm: 1.4186 | dt: 1678.33ms | tok/sec: 2440.52\n",
            "step  326 | loss: 1.602798 | lr 2.3589e-04 | norm: 1.4130 | dt: 1687.64ms | tok/sec: 2427.06\n",
            "step  327 | loss: 1.685892 | lr 2.3412e-04 | norm: 1.5477 | dt: 1679.93ms | tok/sec: 2438.19\n",
            "step  328 | loss: 1.432753 | lr 2.3236e-04 | norm: 1.1336 | dt: 1677.87ms | tok/sec: 2441.20\n",
            "step  329 | loss: 1.536611 | lr 2.3061e-04 | norm: 1.1255 | dt: 1677.17ms | tok/sec: 2442.20\n",
            "step  330 | loss: 1.488342 | lr 2.2886e-04 | norm: 1.2901 | dt: 1681.65ms | tok/sec: 2435.71\n",
            "step  331 | loss: 1.440733 | lr 2.2711e-04 | norm: 1.2536 | dt: 1674.31ms | tok/sec: 2446.38\n",
            "step  332 | loss: 1.547477 | lr 2.2537e-04 | norm: 1.3940 | dt: 1684.10ms | tok/sec: 2432.16\n",
            "step  333 | loss: 1.465942 | lr 2.2364e-04 | norm: 1.3045 | dt: 1676.40ms | tok/sec: 2443.33\n",
            "step  334 | loss: 1.670959 | lr 2.2191e-04 | norm: 1.3935 | dt: 1682.17ms | tok/sec: 2434.94\n",
            "step  335 | loss: 1.523907 | lr 2.2018e-04 | norm: 1.3713 | dt: 1677.79ms | tok/sec: 2441.31\n",
            "step  336 | loss: 1.528016 | lr 2.1846e-04 | norm: 1.2585 | dt: 1676.12ms | tok/sec: 2443.74\n",
            "step  337 | loss: 1.533156 | lr 2.1675e-04 | norm: 1.3247 | dt: 1677.62ms | tok/sec: 2441.55\n",
            "step  338 | loss: 1.275788 | lr 2.1504e-04 | norm: 1.1192 | dt: 1682.55ms | tok/sec: 2434.40\n",
            "step  339 | loss: 1.539465 | lr 2.1334e-04 | norm: 1.5590 | dt: 1684.28ms | tok/sec: 2431.89\n",
            "step  340 | loss: 1.397255 | lr 2.1164e-04 | norm: 1.2362 | dt: 1681.27ms | tok/sec: 2436.25\n",
            "step  341 | loss: 1.397246 | lr 2.0995e-04 | norm: 1.0909 | dt: 1673.98ms | tok/sec: 2446.87\n",
            "step  342 | loss: 1.499385 | lr 2.0826e-04 | norm: 1.3695 | dt: 1674.08ms | tok/sec: 2446.72\n",
            "step  343 | loss: 1.492062 | lr 2.0658e-04 | norm: 1.4743 | dt: 1675.75ms | tok/sec: 2444.28\n",
            "step  344 | loss: 1.356487 | lr 2.0491e-04 | norm: 1.2150 | dt: 1683.47ms | tok/sec: 2433.07\n",
            "step  345 | loss: 1.514688 | lr 2.0324e-04 | norm: 1.5113 | dt: 1675.21ms | tok/sec: 2445.06\n",
            "step  346 | loss: 1.378102 | lr 2.0158e-04 | norm: 1.2934 | dt: 1675.01ms | tok/sec: 2445.36\n",
            "step  347 | loss: 1.310270 | lr 1.9993e-04 | norm: 1.1772 | dt: 1674.97ms | tok/sec: 2445.41\n",
            "step  348 | loss: 1.478393 | lr 1.9828e-04 | norm: 1.2049 | dt: 1679.54ms | tok/sec: 2438.76\n",
            "step  349 | loss: 1.639695 | lr 1.9664e-04 | norm: 1.4590 | dt: 1677.85ms | tok/sec: 2441.22\n",
            "step  350 | loss: 1.452435 | lr 1.9500e-04 | norm: 1.4663 | dt: 1678.04ms | tok/sec: 2440.94\n",
            "step  351 | loss: 1.426263 | lr 1.9337e-04 | norm: 1.3043 | dt: 1686.00ms | tok/sec: 2429.43\n",
            "step  352 | loss: 1.394238 | lr 1.9175e-04 | norm: 1.3383 | dt: 1677.80ms | tok/sec: 2441.29\n",
            "step  353 | loss: 1.400432 | lr 1.9013e-04 | norm: 1.2764 | dt: 1683.40ms | tok/sec: 2433.17\n",
            "step  354 | loss: 1.414370 | lr 1.8852e-04 | norm: 1.3871 | dt: 1680.71ms | tok/sec: 2437.07\n",
            "step  355 | loss: 1.572810 | lr 1.8692e-04 | norm: 1.2871 | dt: 1676.98ms | tok/sec: 2442.48\n",
            "step  356 | loss: 1.540467 | lr 1.8533e-04 | norm: 1.4565 | dt: 1675.68ms | tok/sec: 2444.38\n",
            "step  357 | loss: 1.313135 | lr 1.8374e-04 | norm: 1.4381 | dt: 1680.47ms | tok/sec: 2437.42\n",
            "step  358 | loss: 1.251015 | lr 1.8216e-04 | norm: 1.2581 | dt: 1677.73ms | tok/sec: 2441.39\n",
            "step  359 | loss: 1.491014 | lr 1.8058e-04 | norm: 1.3916 | dt: 1680.37ms | tok/sec: 2437.56\n",
            "step  360 | loss: 1.449213 | lr 1.7902e-04 | norm: 1.4370 | dt: 1678.85ms | tok/sec: 2439.76\n",
            "step  361 | loss: 1.335230 | lr 1.7746e-04 | norm: 1.3556 | dt: 1676.94ms | tok/sec: 2442.55\n",
            "step  362 | loss: 1.367361 | lr 1.7591e-04 | norm: 1.3051 | dt: 1678.51ms | tok/sec: 2440.25\n",
            "step  363 | loss: 1.271030 | lr 1.7436e-04 | norm: 1.2456 | dt: 1675.12ms | tok/sec: 2445.20\n",
            "step  364 | loss: 1.299405 | lr 1.7283e-04 | norm: 1.2259 | dt: 1675.06ms | tok/sec: 2445.28\n",
            "step  365 | loss: 1.425937 | lr 1.7130e-04 | norm: 1.3647 | dt: 1685.91ms | tok/sec: 2429.54\n",
            "step  366 | loss: 1.261692 | lr 1.6978e-04 | norm: 1.5573 | dt: 1679.05ms | tok/sec: 2439.48\n",
            "step  367 | loss: 1.249502 | lr 1.6826e-04 | norm: 1.2269 | dt: 1680.10ms | tok/sec: 2437.95\n",
            "step  368 | loss: 1.321369 | lr 1.6676e-04 | norm: 1.4665 | dt: 1675.73ms | tok/sec: 2444.31\n",
            "step  369 | loss: 1.240192 | lr 1.6526e-04 | norm: 1.2813 | dt: 1679.14ms | tok/sec: 2439.34\n",
            "step  370 | loss: 1.197865 | lr 1.6377e-04 | norm: 1.1857 | dt: 1681.43ms | tok/sec: 2436.02\n",
            "step  371 | loss: 1.419721 | lr 1.6229e-04 | norm: 1.3680 | dt: 1683.01ms | tok/sec: 2433.74\n",
            "step  372 | loss: 1.330458 | lr 1.6082e-04 | norm: 1.4032 | dt: 1677.91ms | tok/sec: 2441.14\n",
            "step  373 | loss: 1.243103 | lr 1.5935e-04 | norm: 1.3199 | dt: 1680.79ms | tok/sec: 2436.95\n",
            "step  374 | loss: 1.262967 | lr 1.5790e-04 | norm: 1.3220 | dt: 1672.28ms | tok/sec: 2449.35\n",
            "step  375 | loss: 1.199921 | lr 1.5645e-04 | norm: 1.1778 | dt: 1679.05ms | tok/sec: 2439.47\n",
            "step  376 | loss: 1.151846 | lr 1.5501e-04 | norm: 1.0756 | dt: 1680.76ms | tok/sec: 2436.99\n",
            "step  377 | loss: 1.270716 | lr 1.5358e-04 | norm: 1.6718 | dt: 1685.68ms | tok/sec: 2429.88\n",
            "step  378 | loss: 1.200432 | lr 1.5215e-04 | norm: 1.2165 | dt: 1690.14ms | tok/sec: 2423.47\n",
            "step  379 | loss: 1.194681 | lr 1.5074e-04 | norm: 1.3004 | dt: 1677.51ms | tok/sec: 2441.71\n",
            "step  380 | loss: 1.154131 | lr 1.4933e-04 | norm: 1.2053 | dt: 1679.07ms | tok/sec: 2439.45\n",
            "step  381 | loss: 1.411376 | lr 1.4794e-04 | norm: 1.3964 | dt: 1680.16ms | tok/sec: 2437.86\n",
            "step  382 | loss: 1.202530 | lr 1.4655e-04 | norm: 1.2197 | dt: 1683.98ms | tok/sec: 2432.33\n",
            "step  383 | loss: 1.131912 | lr 1.4517e-04 | norm: 1.2579 | dt: 1678.46ms | tok/sec: 2440.34\n",
            "step  384 | loss: 1.293095 | lr 1.4380e-04 | norm: 1.4945 | dt: 1684.48ms | tok/sec: 2431.61\n",
            "step  385 | loss: 1.280545 | lr 1.4244e-04 | norm: 1.3681 | dt: 1683.82ms | tok/sec: 2432.57\n",
            "step  386 | loss: 1.275773 | lr 1.4109e-04 | norm: 1.2638 | dt: 1686.29ms | tok/sec: 2429.00\n",
            "step  387 | loss: 1.095554 | lr 1.3975e-04 | norm: 1.2280 | dt: 1679.33ms | tok/sec: 2439.06\n",
            "step  388 | loss: 1.203928 | lr 1.3842e-04 | norm: 1.3334 | dt: 1679.92ms | tok/sec: 2438.22\n",
            "step  389 | loss: 1.138267 | lr 1.3709e-04 | norm: 1.2693 | dt: 1676.04ms | tok/sec: 2443.86\n",
            "step  390 | loss: 1.058771 | lr 1.3578e-04 | norm: 1.1533 | dt: 1684.88ms | tok/sec: 2431.03\n",
            "step  391 | loss: 1.180942 | lr 1.3447e-04 | norm: 1.4425 | dt: 1680.31ms | tok/sec: 2437.65\n",
            "step  392 | loss: 1.140453 | lr 1.3318e-04 | norm: 1.1869 | dt: 1693.12ms | tok/sec: 2419.21\n",
            "step  393 | loss: 1.088004 | lr 1.3189e-04 | norm: 1.3633 | dt: 1683.69ms | tok/sec: 2432.75\n",
            "step  394 | loss: 1.280061 | lr 1.3062e-04 | norm: 1.2846 | dt: 1682.10ms | tok/sec: 2435.05\n",
            "step  395 | loss: 1.096339 | lr 1.2935e-04 | norm: 1.3794 | dt: 1688.81ms | tok/sec: 2425.38\n",
            "step  396 | loss: 1.039813 | lr 1.2809e-04 | norm: 1.2291 | dt: 1689.33ms | tok/sec: 2424.63\n",
            "step  397 | loss: 1.142272 | lr 1.2685e-04 | norm: 1.0875 | dt: 1671.70ms | tok/sec: 2450.20\n",
            "step  398 | loss: 1.137717 | lr 1.2561e-04 | norm: 1.1866 | dt: 1670.30ms | tok/sec: 2452.26\n",
            "step  399 | loss: 1.036315 | lr 1.2438e-04 | norm: 1.1830 | dt: 1680.60ms | tok/sec: 2437.23\n",
            "step  400 | loss: 1.120140 | lr 1.2317e-04 | norm: 1.1871 | dt: 1684.88ms | tok/sec: 2431.03\n",
            "step  401 | loss: 1.084044 | lr 1.2196e-04 | norm: 1.0603 | dt: 1677.69ms | tok/sec: 2441.46\n",
            "step  402 | loss: 1.155122 | lr 1.2076e-04 | norm: 1.3345 | dt: 1678.65ms | tok/sec: 2440.05\n",
            "step  403 | loss: 1.216442 | lr 1.1958e-04 | norm: 1.2720 | dt: 1678.76ms | tok/sec: 2439.89\n",
            "step  404 | loss: 1.182326 | lr 1.1840e-04 | norm: 1.3915 | dt: 1681.01ms | tok/sec: 2436.63\n",
            "step  405 | loss: 1.144604 | lr 1.1724e-04 | norm: 1.2182 | dt: 1680.37ms | tok/sec: 2437.56\n",
            "step  406 | loss: 1.183639 | lr 1.1608e-04 | norm: 1.3298 | dt: 1676.24ms | tok/sec: 2443.56\n",
            "step  407 | loss: 1.171586 | lr 1.1494e-04 | norm: 1.4202 | dt: 1687.10ms | tok/sec: 2427.83\n",
            "step  408 | loss: 1.128029 | lr 1.1380e-04 | norm: 1.2903 | dt: 1685.80ms | tok/sec: 2429.71\n",
            "step  409 | loss: 1.128814 | lr 1.1268e-04 | norm: 1.2045 | dt: 1678.36ms | tok/sec: 2440.48\n",
            "step  410 | loss: 1.036875 | lr 1.1157e-04 | norm: 1.1379 | dt: 1682.85ms | tok/sec: 2433.97\n",
            "step  411 | loss: 1.024408 | lr 1.1046e-04 | norm: 1.1592 | dt: 1682.90ms | tok/sec: 2433.89\n",
            "step  412 | loss: 0.999129 | lr 1.0937e-04 | norm: 1.1728 | dt: 1682.68ms | tok/sec: 2434.22\n",
            "step  413 | loss: 0.989848 | lr 1.0829e-04 | norm: 1.1368 | dt: 1687.83ms | tok/sec: 2426.79\n",
            "step  414 | loss: 0.897179 | lr 1.0722e-04 | norm: 1.0591 | dt: 1681.78ms | tok/sec: 2435.52\n",
            "step  415 | loss: 1.139015 | lr 1.0616e-04 | norm: 1.2109 | dt: 1678.34ms | tok/sec: 2440.50\n",
            "step  416 | loss: 1.019860 | lr 1.0511e-04 | norm: 1.0339 | dt: 1678.11ms | tok/sec: 2440.84\n",
            "step  417 | loss: 0.970832 | lr 1.0407e-04 | norm: 1.2596 | dt: 1674.84ms | tok/sec: 2445.61\n",
            "step  418 | loss: 1.148223 | lr 1.0305e-04 | norm: 1.2573 | dt: 1678.40ms | tok/sec: 2440.42\n",
            "step  419 | loss: 1.071760 | lr 1.0203e-04 | norm: 1.3314 | dt: 1692.69ms | tok/sec: 2419.82\n",
            "step  420 | loss: 0.998918 | lr 1.0103e-04 | norm: 1.1388 | dt: 1679.51ms | tok/sec: 2438.81\n",
            "step  421 | loss: 1.082000 | lr 1.0003e-04 | norm: 1.2228 | dt: 1679.74ms | tok/sec: 2438.47\n",
            "step  422 | loss: 0.971614 | lr 9.9052e-05 | norm: 1.1292 | dt: 1676.93ms | tok/sec: 2442.56\n",
            "step  423 | loss: 1.072186 | lr 9.8081e-05 | norm: 1.2905 | dt: 1689.36ms | tok/sec: 2424.59\n",
            "step  424 | loss: 1.046623 | lr 9.7121e-05 | norm: 1.2188 | dt: 1682.30ms | tok/sec: 2434.76\n",
            "step  425 | loss: 1.111461 | lr 9.6173e-05 | norm: 1.2727 | dt: 1688.58ms | tok/sec: 2425.71\n",
            "step  426 | loss: 0.967529 | lr 9.5236e-05 | norm: 1.1359 | dt: 1686.53ms | tok/sec: 2428.66\n",
            "step  427 | loss: 0.900600 | lr 9.4311e-05 | norm: 1.1313 | dt: 1681.37ms | tok/sec: 2436.11\n",
            "step  428 | loss: 0.916259 | lr 9.3397e-05 | norm: 1.0728 | dt: 1681.25ms | tok/sec: 2436.28\n",
            "step  429 | loss: 1.009572 | lr 9.2495e-05 | norm: 1.1147 | dt: 1681.96ms | tok/sec: 2435.25\n",
            "step  430 | loss: 1.043031 | lr 9.1604e-05 | norm: 1.1730 | dt: 1684.23ms | tok/sec: 2431.97\n",
            "step  431 | loss: 0.989644 | lr 9.0725e-05 | norm: 1.3063 | dt: 1690.09ms | tok/sec: 2423.54\n",
            "step  432 | loss: 0.980034 | lr 8.9858e-05 | norm: 1.2334 | dt: 1679.26ms | tok/sec: 2439.17\n",
            "step  433 | loss: 0.924372 | lr 8.9002e-05 | norm: 1.2427 | dt: 1678.21ms | tok/sec: 2440.70\n",
            "step  434 | loss: 1.025491 | lr 8.8158e-05 | norm: 1.2027 | dt: 1674.33ms | tok/sec: 2446.35\n",
            "step  435 | loss: 1.067528 | lr 8.7326e-05 | norm: 1.2107 | dt: 1677.31ms | tok/sec: 2442.00\n",
            "step  436 | loss: 0.941406 | lr 8.6505e-05 | norm: 1.1447 | dt: 1683.89ms | tok/sec: 2432.47\n",
            "step  437 | loss: 0.952526 | lr 8.5697e-05 | norm: 1.2703 | dt: 1677.18ms | tok/sec: 2442.20\n",
            "step  438 | loss: 0.882192 | lr 8.4900e-05 | norm: 1.2813 | dt: 1682.41ms | tok/sec: 2434.60\n",
            "step  439 | loss: 0.888519 | lr 8.4115e-05 | norm: 1.0494 | dt: 1682.16ms | tok/sec: 2434.97\n",
            "step  440 | loss: 0.922111 | lr 8.3343e-05 | norm: 1.1554 | dt: 1675.44ms | tok/sec: 2444.73\n",
            "step  441 | loss: 0.891808 | lr 8.2582e-05 | norm: 1.2353 | dt: 1684.89ms | tok/sec: 2431.02\n",
            "step  442 | loss: 0.803617 | lr 8.1833e-05 | norm: 0.9972 | dt: 1680.67ms | tok/sec: 2437.12\n",
            "step  443 | loss: 0.995844 | lr 8.1097e-05 | norm: 1.2808 | dt: 1683.04ms | tok/sec: 2433.69\n",
            "step  444 | loss: 0.911588 | lr 8.0373e-05 | norm: 1.2792 | dt: 1690.30ms | tok/sec: 2423.24\n",
            "step  445 | loss: 0.853635 | lr 7.9660e-05 | norm: 1.1656 | dt: 1682.01ms | tok/sec: 2435.18\n",
            "step  446 | loss: 0.851885 | lr 7.8960e-05 | norm: 0.9914 | dt: 1687.23ms | tok/sec: 2427.65\n",
            "step  447 | loss: 0.884402 | lr 7.8273e-05 | norm: 1.2058 | dt: 1684.70ms | tok/sec: 2431.29\n",
            "step  448 | loss: 0.957741 | lr 7.7597e-05 | norm: 1.1437 | dt: 1683.54ms | tok/sec: 2432.97\n",
            "step  449 | loss: 0.747405 | lr 7.6934e-05 | norm: 0.9875 | dt: 1685.80ms | tok/sec: 2429.70\n",
            "step  450 | loss: 0.893224 | lr 7.6283e-05 | norm: 1.1801 | dt: 1685.65ms | tok/sec: 2429.93\n",
            "step  451 | loss: 0.877834 | lr 7.5644e-05 | norm: 1.2271 | dt: 1681.14ms | tok/sec: 2436.44\n",
            "step  452 | loss: 0.936700 | lr 7.5018e-05 | norm: 1.1983 | dt: 1684.81ms | tok/sec: 2431.13\n",
            "step  453 | loss: 0.821879 | lr 7.4405e-05 | norm: 1.0530 | dt: 1682.88ms | tok/sec: 2433.93\n",
            "step  454 | loss: 0.836618 | lr 7.3803e-05 | norm: 1.1316 | dt: 1674.63ms | tok/sec: 2445.92\n",
            "step  455 | loss: 0.823740 | lr 7.3215e-05 | norm: 1.1893 | dt: 1685.57ms | tok/sec: 2430.04\n",
            "step  456 | loss: 0.864017 | lr 7.2639e-05 | norm: 1.2033 | dt: 1687.27ms | tok/sec: 2427.60\n",
            "step  457 | loss: 0.781390 | lr 7.2075e-05 | norm: 1.0497 | dt: 1677.53ms | tok/sec: 2441.68\n",
            "step  458 | loss: 0.781507 | lr 7.1524e-05 | norm: 1.0334 | dt: 1681.29ms | tok/sec: 2436.22\n",
            "step  459 | loss: 0.794267 | lr 7.0985e-05 | norm: 1.0781 | dt: 1680.56ms | tok/sec: 2437.28\n",
            "step  460 | loss: 1.034901 | lr 7.0459e-05 | norm: 1.4324 | dt: 1684.48ms | tok/sec: 2431.62\n",
            "step  461 | loss: 0.911705 | lr 6.9946e-05 | norm: 1.2828 | dt: 1678.46ms | tok/sec: 2440.33\n",
            "step  462 | loss: 0.856152 | lr 6.9446e-05 | norm: 1.0647 | dt: 1682.83ms | tok/sec: 2433.99\n",
            "step  463 | loss: 0.792284 | lr 6.8958e-05 | norm: 1.1004 | dt: 1682.90ms | tok/sec: 2433.90\n",
            "step  464 | loss: 0.754217 | lr 6.8483e-05 | norm: 0.9823 | dt: 1676.47ms | tok/sec: 2443.24\n",
            "step  465 | loss: 0.798002 | lr 6.8020e-05 | norm: 1.0687 | dt: 1680.18ms | tok/sec: 2437.83\n",
            "step  466 | loss: 1.011220 | lr 6.7571e-05 | norm: 1.3132 | dt: 1683.60ms | tok/sec: 2432.88\n",
            "step  467 | loss: 0.795897 | lr 6.7134e-05 | norm: 1.2832 | dt: 1679.97ms | tok/sec: 2438.14\n",
            "step  468 | loss: 0.743724 | lr 6.6710e-05 | norm: 1.0775 | dt: 1680.66ms | tok/sec: 2437.14\n",
            "step  469 | loss: 0.796772 | lr 6.6298e-05 | norm: 1.1060 | dt: 1679.89ms | tok/sec: 2438.26\n",
            "step  470 | loss: 0.838423 | lr 6.5900e-05 | norm: 1.2450 | dt: 1684.52ms | tok/sec: 2431.56\n",
            "step  471 | loss: 0.849503 | lr 6.5515e-05 | norm: 1.2999 | dt: 1676.71ms | tok/sec: 2442.88\n",
            "step  472 | loss: 0.790640 | lr 6.5142e-05 | norm: 1.1531 | dt: 1684.74ms | tok/sec: 2431.23\n",
            "step  473 | loss: 0.886716 | lr 6.4782e-05 | norm: 1.2124 | dt: 1677.54ms | tok/sec: 2441.67\n",
            "step  474 | loss: 0.848728 | lr 6.4436e-05 | norm: 1.2079 | dt: 1681.13ms | tok/sec: 2436.45\n",
            "step  475 | loss: 0.828568 | lr 6.4102e-05 | norm: 1.3590 | dt: 1675.22ms | tok/sec: 2445.05\n",
            "step  476 | loss: 0.842556 | lr 6.3781e-05 | norm: 1.3096 | dt: 1674.06ms | tok/sec: 2446.74\n",
            "step  477 | loss: 0.756590 | lr 6.3473e-05 | norm: 1.4346 | dt: 1679.18ms | tok/sec: 2439.29\n",
            "step  478 | loss: 0.901444 | lr 6.3178e-05 | norm: 1.1754 | dt: 1687.11ms | tok/sec: 2427.82\n",
            "step  479 | loss: 0.730553 | lr 6.2896e-05 | norm: 1.0592 | dt: 1676.47ms | tok/sec: 2443.23\n",
            "step  480 | loss: 0.826497 | lr 6.2628e-05 | norm: 1.0869 | dt: 1676.92ms | tok/sec: 2442.58\n",
            "step  481 | loss: 0.790359 | lr 6.2372e-05 | norm: 1.1573 | dt: 1684.12ms | tok/sec: 2432.13\n",
            "step  482 | loss: 0.734748 | lr 6.2129e-05 | norm: 1.1352 | dt: 1689.32ms | tok/sec: 2424.65\n",
            "step  483 | loss: 0.916569 | lr 6.1899e-05 | norm: 1.4032 | dt: 1681.30ms | tok/sec: 2436.21\n",
            "step  484 | loss: 0.834642 | lr 6.1683e-05 | norm: 1.2572 | dt: 1677.01ms | tok/sec: 2442.44\n",
            "step  485 | loss: 0.763753 | lr 6.1479e-05 | norm: 1.1688 | dt: 1678.41ms | tok/sec: 2440.40\n",
            "step  486 | loss: 0.719163 | lr 6.1289e-05 | norm: 1.2097 | dt: 1680.03ms | tok/sec: 2438.05\n",
            "step  487 | loss: 0.735994 | lr 6.1111e-05 | norm: 1.0958 | dt: 1681.09ms | tok/sec: 2436.52\n",
            "step  488 | loss: 0.722222 | lr 6.0947e-05 | norm: 1.3601 | dt: 1682.72ms | tok/sec: 2434.16\n",
            "step  489 | loss: 0.814659 | lr 6.0796e-05 | norm: 1.2166 | dt: 1681.88ms | tok/sec: 2435.37\n",
            "step  490 | loss: 0.821037 | lr 6.0658e-05 | norm: 1.1691 | dt: 1680.89ms | tok/sec: 2436.80\n",
            "step  491 | loss: 0.746809 | lr 6.0533e-05 | norm: 1.0749 | dt: 1684.79ms | tok/sec: 2431.16\n",
            "step  492 | loss: 0.789640 | lr 6.0421e-05 | norm: 1.1974 | dt: 1683.50ms | tok/sec: 2433.03\n",
            "step  493 | loss: 0.747596 | lr 6.0322e-05 | norm: 1.2837 | dt: 1677.89ms | tok/sec: 2441.16\n",
            "step  494 | loss: 0.724750 | lr 6.0237e-05 | norm: 1.1106 | dt: 1681.44ms | tok/sec: 2436.01\n",
            "step  495 | loss: 0.812240 | lr 6.0164e-05 | norm: 1.1673 | dt: 1676.31ms | tok/sec: 2443.47\n",
            "step  496 | loss: 0.798656 | lr 6.0105e-05 | norm: 1.2170 | dt: 1682.10ms | tok/sec: 2435.05\n",
            "step  497 | loss: 0.852305 | lr 6.0059e-05 | norm: 1.3016 | dt: 1680.89ms | tok/sec: 2436.80\n",
            "step  498 | loss: 0.742622 | lr 6.0026e-05 | norm: 1.3376 | dt: 1680.72ms | tok/sec: 2437.04\n",
            "step  499 | loss: 0.704724 | lr 6.0007e-05 | norm: 1.0973 | dt: 1681.29ms | tok/sec: 2436.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "GOMWNbwKZrBC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_perplexity(model, data_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(data_loader, desc=\"Calculating perplexity\"):\n",
        "            # Move the batch to the appropriate device (CPU/GPU)\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # Forward pass: Get logits and loss from the model\n",
        "            logits, loss = model(x, y)\n",
        "\n",
        "            # Accumulate the loss\n",
        "            total_loss += loss.item() * x.size(0) * x.size(1)  # Multiply by batch size and sequence length\n",
        "            total_tokens += x.numel()  # Count the total number of tokens\n",
        "\n",
        "    # Ensure total_tokens is not zero to avoid division by zero\n",
        "    if total_tokens == 0:\n",
        "        print(\"No tokens found, perplexity cannot be computed.\")\n",
        "        return float('inf')\n",
        "\n",
        "    # Calculate average loss (cross-entropy loss per token)\n",
        "    average_loss = total_loss / total_tokens\n",
        "\n",
        "    # Calculate perplexity: perplexity = exp(average loss)\n",
        "    perplexity = torch.exp(torch.tensor(average_loss, device=device))\n",
        "\n",
        "    # Print final results\n",
        "    print(f\"Total Loss: {total_loss:.4f}, Total Tokens: {total_tokens}, Average Loss: {average_loss:.4f}\")\n",
        "    return perplexity.item()\n",
        "\n",
        "# Example usage:\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create dataset for test data\n",
        "test_dataset = ImprovedDataset(file_path='test.txt', config=config, train_mode=False)\n",
        "\n",
        "# Create DataLoader\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=config.num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Assuming you have a trained model loaded on the correct device\n",
        "perplexity = calculate_perplexity(model, test_loader, device)\n",
        "print(f\"Perplexity of the model on test data: {perplexity:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ExXic09wSZ8",
        "outputId": "fbf5e857-cbf9-4fa1-b9af-5086fd15898d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading from cache...\n",
            "Loaded 8192 tokens from test.txt\n",
            "1 epoch = 2 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating perplexity: 100%|██████████| 1792/1792 [13:09<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Loss: 44259714.0391, Total Tokens: 7340032, Average Loss: 6.0299\n",
            "Perplexity of the model on test data: 415.6767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eg53CtREwSca"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # -----------------------------------------------------------------------------\n",
        "# num_return_sequences = 5\n",
        "# max_length = 30\n",
        "\n",
        "# # model = GPT.from_pretrained('gpt2')\n",
        "# # model.eval()\n",
        "# # model.to('cuda')\n",
        "\n",
        "# # prefix tokens\n",
        "# enc = tiktoken.get_encoding('gpt2')\n",
        "# tokens = enc.encode(\"Hello,\")\n",
        "# tokens = torch.tensor(tokens, dtype=torch.long) # (8,)\n",
        "# tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1) # (5, 8)\n",
        "# x = tokens.to('cuda')\n",
        "\n",
        "# # generate! right now x is (B, T) where B = 5, T = 8\n",
        "# # set the seed to 42\n",
        "# torch.manual_seed(42)\n",
        "# torch.cuda.manual_seed(42)\n",
        "# while x.size(1) < max_length:\n",
        "#     # forward the model to get the logits\n",
        "#     with torch.no_grad():\n",
        "#         logits = model(x) # (B, T, vocab_size)\n",
        "#         # take the logits at the last position\n",
        "#         logits = logits[:, -1, :] # (B, vocab_size)\n",
        "#         # get the probabilities\n",
        "#         probs = F.softmax(logits, dim=-1)\n",
        "#         # do top-k sampling of 50 (huggingface pipeline default)\n",
        "#         # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
        "#         topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
        "#         # select a token from the top-k probabilities\n",
        "#         # note: multinomial does not demand the input to sum to 1\n",
        "#         ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
        "#         # gather the corresponding indices\n",
        "#         xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
        "#         # append to the sequence\n",
        "#         x = torch.cat((x, xcol), dim=1)\n",
        "\n",
        "# # print the generated text\n",
        "# for i in range(num_return_sequences):\n",
        "#     tokens = x[i, :max_length].tolist()\n",
        "#     decoded = enc.decode(tokens)\n",
        "#     print(\">\", decoded)\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Parameters\n",
        "num_return_sequences = 5\n",
        "max_length = 30\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.eval()\n",
        "model.to('cuda')\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Prefix tokens\n",
        "tokens = tokenizer.encode(\"Hello,\", return_tensors='pt')  # (1, T)\n",
        "tokens = tokens.repeat(num_return_sequences, 1)  # (B, T) where B = num_return_sequences\n",
        "x = tokens.to('cuda')  # Move tokens to GPU\n",
        "\n",
        "# Set the seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Generate text\n",
        "while x.size(1) < max_length:\n",
        "    with torch.no_grad():\n",
        "        outputs = model(x)  # `outputs` is a tuple\n",
        "        logits = outputs.logits  # Extract logits (B, T, vocab_size)\n",
        "        logits = logits[:, -1, :]  # Take logits at the last position (B, vocab_size)\n",
        "\n",
        "        probs = F.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
        "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)  # Top-k sampling\n",
        "\n",
        "        ix = torch.multinomial(topk_probs, 1)  # Sample from top-k probabilities (B, 1)\n",
        "        xcol = torch.gather(topk_indices, -1, ix)  # Gather indices of sampled tokens (B, 1)\n",
        "        x = torch.cat((x, xcol), dim=1)  # Append sampled tokens to the sequence (B, T+1)\n",
        "\n",
        "# Print the generated text\n",
        "for i in range(num_return_sequences):\n",
        "    tokens = x[i, :].tolist()\n",
        "    decoded = tokenizer.decode(tokens, skip_special_tokens=True)\n",
        "    print(\">\", decoded)\n"
      ],
      "metadata": {
        "id": "NFaJFeJylzXh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533,
          "referenced_widgets": [
            "de2e4bb92ce34023bc15b10004f2b2f6",
            "56808b42156d4aea8146f9d69bbe9844",
            "c93aa66bb5624939a95f260e18fbe5dc",
            "93d7b5a825424a269992be094ff9ac4e",
            "d2cc1a6d3f3042c3af505ddcb6718dcc",
            "fe20cd549d454ebc95e7734bfa4767a6",
            "30aa1de8348247259640eb107d6a1ce0",
            "1a492652a24b4fe2aae4a5c7deeef5c7",
            "88d7599342ba41318c2541ffb7b2d49f",
            "b1e6ac5df5064d9fb8ce98b78fc1414b",
            "fc541ae92a524981b439759dfac89291",
            "8954034f5e704d87911ad7155393fe63",
            "0ef704e034614b2a9b00a7db918cf74c",
            "fed5d7f3c02849378d4e46410e1e9acd",
            "3a8b0e7e269d48cfb5e7ebd36b7985f1",
            "764c7b4ad5ab4b56b824ad91f113b351",
            "2bbdd64d0b67429eba3ed91e601ab56f",
            "a6586a633e524e51b5b88099a1532c2d",
            "19a267ad9f6c46d2b0550bfd64b0cac2",
            "849d88a3c17e4d80b776ca152b17852a",
            "c6f3ffd333f646f88dfac440261d513b",
            "a4375e5aa9ef4146845d67bc6b11035c",
            "00199614e53147fab867ff80c017eea7",
            "296bfcd9f0914a3ea1f28cc60538a9f5",
            "7b4883c0cf1a4c019b1509c184f6e990",
            "f7e254535dbc48ee9be8326140c6e750",
            "608c27c0f1bc4134b87a6c39a3972bfd",
            "d09fca86d2314406baf7610bf0d5ce07",
            "304ffa4b6e724f4d9809ca676ecf7b5f",
            "d79e5a76d55a43168c82c829116eba67",
            "fb6504ad243c4a12994f7709d10ab1dd",
            "3f9e19761a484335a396b47aacea90c7",
            "d52027d42380457199eee0df3da6cbd1",
            "dce1bb9da22b471f9e91eadf7d53355f",
            "dfe750aa0acc4a238f479767ce506cba",
            "66f18a7d8ca84f65b2f2eee8bcd30893",
            "fe0ab034a86a4d5ab55b1f4c3a3ff224",
            "3e4d5919f4bf4d0d92239d8503dd41b1",
            "53e523508600427aa5002f7de2fdf291",
            "6992cbb9e18c4bc493ad942da8a7f652",
            "7a701bcc94984047bff110e265ad24e8",
            "b8e3403792e241fdac24551c15cdc135",
            "154599ada7ee4aa786ac5fe35d21df55",
            "f66aec5360ca404fa956fbd4e39bd1a2",
            "b74046edc8d44f4094ab319d9db436de",
            "d05eb9b8e8d4406a939272ff8c16efe4",
            "cbb075e1cbd4451e896cc8b343593c49",
            "d7133f14a10e4f77a75ab84b40b43de4",
            "aa4f39b06f854038a1d20993ee67c824",
            "83650704301c41e2ab1bce8ca8ae23dc",
            "2e31b41dd57a4ca292eb53ea0bcc7407",
            "09916d5762734c74b698004f87050fc6",
            "efbf3b2df0184f06a204e1db3398be58",
            "c29b24286192467dbdb31f137166e510",
            "8173c96ad2474ad8ad2ba8021c897379",
            "a250f8d4f2f5482fb0d84eed2d61ec8f",
            "e9688973c4e04a0c8c85400acb733672",
            "caecfed1d336416e920a76419c436890",
            "1459c353052e4952a795ac03d0477273",
            "24a758951a0e401b8848a632c6316b7c",
            "1d01964b34794343a42c6a96bbf9ffd8",
            "474b103f2eb94b189097ffb052f93751",
            "319138a7940f40098c71389db8a7ce0b",
            "685090c92f42481cb0d44c2ce4a16f82",
            "440bbd6712494f3c8f1ffe53e486ce70",
            "7c66e8cb0d5c437b95dcad0d7e9d2db6",
            "1e09fa5c3de44698bc0e34c706c6c070",
            "b791551b28bd46ea8642a6c7801998ab",
            "94ddb1f3b88f46baa727743eae49edb4",
            "3fa2eaedb1744d7e9a08444817f978bf",
            "690c719c185244bfa420e21cafb7cdc9",
            "459e98833168493ebcb7dfa84bf7f787",
            "be4c9c835d2e4c7cbb0cacbcc6b5ef5a",
            "4764e41a21b44b3d97c690814c0eace7",
            "86399e37a2b64e59950200e97f213740",
            "5b3b9a1d5f0b436ea56ea8471af2ff7c",
            "eb7c244e88d6401d9ae5d502dd49169d"
          ]
        },
        "outputId": "3e8f14cf-b0a5-4cd4-eba1-f2731799f1a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de2e4bb92ce34023bc15b10004f2b2f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8954034f5e704d87911ad7155393fe63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00199614e53147fab867ff80c017eea7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dce1bb9da22b471f9e91eadf7d53355f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b74046edc8d44f4094ab319d9db436de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a250f8d4f2f5482fb0d84eed2d61ec8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e09fa5c3de44698bc0e34c706c6c070"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Hello, now that is a great start.\"\n",
            "\n",
            "Houffrani noted his own recent victories over other world champions like Chris Froome and\n",
            "> Hello, why you like this, I am from the UK here… I don't think you are ready to see it. But I'm glad to\n",
            "> Hello, this is me and my mother. You know we are all the same. We are all the same. We all believe in each other.\n",
            "> Hello, we would like to thank you all for supporting H1Z1 today. It will be extremely important to you, everyone, that we continue\n",
            "> Hello,\n",
            "\n",
            "We know that some people get bored from it. You know, people think they can do it. This is good. Well,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RrCwJwnnwSey"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3rpANHpqwShD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ETf_jg0awSjT"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}